{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {
    "papermill": {
     "duration": 0.011609,
     "end_time": "2025-10-14T11:06:30.355921",
     "exception": false,
     "start_time": "2025-10-14T11:06:30.344312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Patch-based 4K Super-Resolution Training with Advanced Memory Debugging\n",
    "\n",
    "## ğŸ“‹ æ¦‚è¿°\n",
    "\n",
    "æœ¬notebookå®ç°äº†ä¸€ä¸ª**åŸºäºpatchçš„è¶…åˆ†è¾¨ç‡è®­ç»ƒç³»ç»Ÿ**ï¼Œä¸“é—¨è®¾è®¡ç”¨äºåœ¨æœ‰é™GPUæ˜¾å­˜ä¸‹è®­ç»ƒ4Kè¶…åˆ†è¾¨ç‡æ¨¡å‹ã€‚\n",
    "\n",
    "### ğŸ¯ ç›®æ ‡ä»»åŠ¡\n",
    "- **è¾“å…¥**: 256Ã—256 ä½åˆ†è¾¨ç‡å›¾åƒ\n",
    "- **è¾“å‡º**: 4096Ã—4096 é«˜åˆ†è¾¨ç‡å›¾åƒ\n",
    "- **æ”¾å¤§å€æ•°**: 16Ã— (åˆ†ä¸¤é˜¶æ®µ: 8Ã— + 2Ã—)\n",
    "\n",
    "### ğŸ”‘ æ ¸å¿ƒç‰¹æ€§\n",
    "\n",
    "#### 1. **Patch-basedè®­ç»ƒç­–ç•¥**\n",
    "- ä¸è®­ç»ƒå®Œæ•´çš„å¤§å›¾åƒï¼Œè€Œæ˜¯è®­ç»ƒå°patch\n",
    "- LR patch: 64Ã—64 â†’ HR patch: 512Ã—512 (8Ã— scale)\n",
    "- è®­ç»ƒæ—¶æ˜¾å­˜å ç”¨æå° (~1-2GB)\n",
    "- æ¨ç†æ—¶ä½¿ç”¨æ»‘åŠ¨çª—å£æ‹¼æ¥å®Œæ•´å›¾åƒ\n",
    "\n",
    "#### 2. **æ˜¾å­˜ç›‘æ§ä¸è°ƒè¯•ç³»ç»Ÿ** ğŸ”\n",
    "- å®æ—¶ç›‘æ§GPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µ\n",
    "- è‡ªåŠ¨æµ‹è¯•æœ€å¤§å¯ç”¨batch size\n",
    "- è¯¦ç»†æ˜¾ç¤ºæ¯ä¸ªè®­ç»ƒæ­¥éª¤çš„æ˜¾å­˜å ç”¨\n",
    "- OOMé”™è¯¯æ—¶ç»™å‡ºå…·ä½“ä¼˜åŒ–å»ºè®®\n",
    "\n",
    "#### 3. **è‡ªé€‚åº”ä¼˜åŒ–æŠ€æœ¯**\n",
    "- **æ··åˆç²¾åº¦è®­ç»ƒ** (FP16): å‡å°‘50%æ˜¾å­˜å ç”¨\n",
    "- **æ¢¯åº¦ç´¯ç§¯**: æ¨¡æ‹Ÿæ›´å¤§batch sizeè€Œä¸å¢åŠ æ˜¾å­˜\n",
    "- **è½»é‡çº§æ¨¡å‹**: æœ€å°åŒ–å‚æ•°é‡å’Œè®¡ç®—é‡\n",
    "- **è‡ªåŠ¨batch sizeè°ƒæ•´**: æ ¹æ®GPUè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜é…ç½®\n",
    "\n",
    "#### 4. **å…¼å®¹æ€§ä¿®å¤**\n",
    "- âœ… ä¿®å¤PyTorchç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜\n",
    "- âœ… æ”¯æŒæ—§ç‰ˆå’Œæ–°ç‰ˆautocast API\n",
    "- âœ… æ”¯æŒæ—§ç‰ˆå’Œæ–°ç‰ˆGradScaler API\n",
    "\n",
    "### ğŸ“Š æ˜¾å­˜å ç”¨ä¼°ç®—\n",
    "\n",
    "| ç»„ä»¶ | æ˜¾å­˜å ç”¨ (batch=1) | æ˜¾å­˜å ç”¨ (batch=4) |\n",
    "|------|-------------------|-------------------|\n",
    "| æ¨¡å‹å‚æ•° | ~50 MB | ~50 MB |\n",
    "| è¾“å…¥LR (64Ã—64) | 0.05 MB | 0.2 MB |\n",
    "| è¾“å‡ºHR (512Ã—512) | 3 MB | 12 MB |\n",
    "| ä¸­é—´æ¿€æ´» | ~200 MB | ~800 MB |\n",
    "| æ¢¯åº¦ | ~50 MB | ~50 MB |\n",
    "| ä¼˜åŒ–å™¨çŠ¶æ€ | ~100 MB | ~100 MB |\n",
    "| **æ€»è®¡** | **~500 MB** | **~1.2 GB** |\n",
    "\n",
    "### ğŸš€ è®­ç»ƒæµç¨‹\n",
    "\n",
    "```\n",
    "Step 1: æ•°æ®å‡†å¤‡\n",
    "  4096Ã—4096 HRå›¾åƒ â†’ éšæœºè£å‰ª512Ã—512 patches\n",
    "  512Ã—512 HR patch â†’ ä¸‹é‡‡æ ·å¾—åˆ°64Ã—64 LR patch\n",
    "\n",
    "Step 2: è®­ç»ƒ8Ã—æ¨¡å‹\n",
    "  è¾“å…¥: 64Ã—64 LR patch\n",
    "  è¾“å‡º: 512Ã—512 SR patch\n",
    "  è®­ç»ƒpatches: 300å¼ å›¾ Ã— 10 patches/å›¾ = 3000 patches\n",
    "\n",
    "Step 3: æ¨ç† (256Ã—256 â†’ 2048Ã—2048)\n",
    "  256Ã—256 â†’ åˆ‡æˆ4Ã—4=16ä¸ª64Ã—64 patches\n",
    "  â†’ æ¯ä¸ªé€šè¿‡8Ã—æ¨¡å‹å¾—åˆ°512Ã—512\n",
    "  â†’ æ‹¼æ¥æˆ2048Ã—2048\n",
    "\n",
    "Step 4: æœ€åæ”¾å¤§ (2048Ã—2048 â†’ 4096Ã—4096)\n",
    "  ä½¿ç”¨bicubicæ’å€¼æˆ–è½»é‡2Ã—æ¨¡å‹\n",
    "```\n",
    "\n",
    "### ğŸ“ˆ é¢„æœŸæ•ˆæœ\n",
    "\n",
    "æ ¹æ®ç±»ä¼¼ä»»åŠ¡çš„ç»éªŒï¼š\n",
    "- **è®­ç»ƒæ—¶é—´**: ~2-4å°æ—¶ (50 epochs, RTX 3090)\n",
    "- **PSNR**: 28-32 dB\n",
    "- **SSIM**: 0.92-0.96\n",
    "- **æ˜¾å­˜å ç”¨**: <2GB\n",
    "\n",
    "### âš™ï¸ é…ç½®è¯´æ˜\n",
    "\n",
    "å¯è°ƒæ•´çš„å…³é”®å‚æ•°ï¼š\n",
    "\n",
    "| å‚æ•° | é»˜è®¤å€¼ | ä½œç”¨ | è°ƒæ•´å»ºè®® |\n",
    "|------|-------|------|---------|\n",
    "| `LR_PATCH_SIZE` | 64 | LR patchå¤§å° | å‡å°â†’é™ä½æ˜¾å­˜ |\n",
    "| `SCALE_FACTOR` | 8 | æ”¾å¤§å€æ•° | å›ºå®šä¸º8 |\n",
    "| `BATCH_SIZE` | è‡ªåŠ¨ | batchå¤§å° | è‡ªåŠ¨æµ‹è¯• |\n",
    "| `BASE_CHANNELS` | 24 | æ¨¡å‹é€šé“æ•° | å‡å°â†’é™ä½æ˜¾å­˜ |\n",
    "| `GRADIENT_ACCUMULATION` | 2 | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° | å¢åŠ â†’æ¨¡æ‹Ÿå¤§batch |\n",
    "\n",
    "---\n",
    "\n",
    "## å¼€å§‹ä½¿ç”¨\n",
    "\n",
    "æŒ‰é¡ºåºæ‰§è¡Œä»¥ä¸‹cellså³å¯å¼€å§‹è®­ç»ƒã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨ï¼š\n",
    "1. æ£€æµ‹GPUæ˜¾å­˜\n",
    "2. æµ‹è¯•æœ€ä¼˜batch size\n",
    "3. æ˜¾ç¤ºè¯¦ç»†çš„æ˜¾å­˜ä½¿ç”¨æƒ…å†µ\n",
    "4. å¼€å§‹è®­ç»ƒå¹¶ä¿å­˜æœ€ä½³æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:30.406268Z",
     "iopub.status.busy": "2025-10-14T11:06:30.405836Z",
     "iopub.status.idle": "2025-10-14T11:06:34.165737Z",
     "shell.execute_reply": "2025-10-14T11:06:34.164608Z"
    },
    "papermill": {
     "duration": 3.772242,
     "end_time": "2025-10-14T11:06:34.167867",
     "exception": false,
     "start_time": "2025-10-14T11:06:30.395625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utils",
   "metadata": {
    "papermill": {
     "duration": 0.008632,
     "end_time": "2025-10-14T11:06:34.186096",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.177464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. GPUæ˜¾å­˜ç›‘æ§å·¥å…·\n",
    "\n",
    "è¿™äº›å·¥å…·å‡½æ•°ç”¨äºå®æ—¶ç›‘æ§å’Œè°ƒè¯•GPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µã€‚\n",
    "\n",
    "### åŠŸèƒ½è¯´æ˜ï¼š\n",
    "\n",
    "1. **print_gpu_memory()**: æ‰“å°å½“å‰GPUæ˜¾å­˜çŠ¶æ€\n",
    "   - `å·²åˆ†é…`: PyTorchå½“å‰ä½¿ç”¨çš„æ˜¾å­˜\n",
    "   - `ä¿ç•™`: PyTorchä»CUDAç¼“å­˜æ± ä¸­ä¿ç•™çš„æ˜¾å­˜\n",
    "   - `å³°å€¼`: è®­ç»ƒè¿‡ç¨‹ä¸­çš„æœ€å¤§æ˜¾å­˜å ç”¨\n",
    "\n",
    "2. **clear_gpu_memory()**: æ¸…ç†GPUæ˜¾å­˜\n",
    "   - è°ƒç”¨Pythonåƒåœ¾å›æ”¶\n",
    "   - æ¸…ç©ºCUDAç¼“å­˜\n",
    "   - åŒæ­¥CUDAæ“ä½œ\n",
    "\n",
    "3. **get_tensor_memory()**: è®¡ç®—å•ä¸ªtensorçš„æ˜¾å­˜å ç”¨\n",
    "   - ç”¨äºåˆ†æå“ªäº›tensorå ç”¨æ˜¾å­˜æœ€å¤š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "memory_utils",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.205785Z",
     "iopub.status.busy": "2025-10-14T11:06:34.205410Z",
     "iopub.status.idle": "2025-10-14T11:06:34.211922Z",
     "shell.execute_reply": "2025-10-14T11:06:34.210943Z"
    },
    "papermill": {
     "duration": 0.018984,
     "end_time": "2025-10-14T11:06:34.213905",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.194921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_gpu_memory(tag=\"\"):\n",
    "    \"\"\"æ‰“å°å½“å‰GPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µ\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        max_allocated = torch.cuda.max_memory_allocated() / 1024**3\n",
    "        print(f\"[{tag}] GPUæ˜¾å­˜: å·²åˆ†é…={allocated:.2f}GB, ä¿ç•™={reserved:.2f}GB, å³°å€¼={max_allocated:.2f}GB\")\n",
    "        return allocated, reserved, max_allocated\n",
    "    return 0, 0, 0\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"æ¸…ç†GPUæ˜¾å­˜\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def get_tensor_memory(tensor):\n",
    "    \"\"\"è·å–tensorå ç”¨çš„æ˜¾å­˜(MB)\"\"\"\n",
    "    return tensor.element_size() * tensor.nelement() / 1024**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "device",
   "metadata": {
    "papermill": {
     "duration": 0.009049,
     "end_time": "2025-10-14T11:06:34.232258",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.223209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. è®¾å¤‡é…ç½®ä¸åˆå§‹çŠ¶æ€æ£€æŸ¥\n",
    "\n",
    "æ£€æµ‹å¯ç”¨çš„GPUè®¾å¤‡ï¼Œå¹¶æ˜¾ç¤ºåˆå§‹æ˜¾å­˜çŠ¶æ€ã€‚\n",
    "\n",
    "### è¾“å‡ºä¿¡æ¯ï¼š\n",
    "- GPUå‹å·\n",
    "- æ€»æ˜¾å­˜å®¹é‡\n",
    "- å½“å‰æ˜¾å­˜ä½¿ç”¨æƒ…å†µ\n",
    "\n",
    "è¿™ä¸€æ­¥ä¼šé‡ç½®æ˜¾å­˜ç»Ÿè®¡ï¼Œç¡®ä¿åç»­çš„æ˜¾å­˜æµ‹è¯•å‡†ç¡®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "device_config",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.253013Z",
     "iopub.status.busy": "2025-10-14T11:06:34.252625Z",
     "iopub.status.idle": "2025-10-14T11:06:34.685121Z",
     "shell.execute_reply": "2025-10-14T11:06:34.684237Z"
    },
    "papermill": {
     "duration": 0.444584,
     "end_time": "2025-10-14T11:06:34.686968",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.242384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½¿ç”¨è®¾å¤‡: cuda\n",
      "GPU: Quadro RTX 6000\n",
      "æ€»æ˜¾å­˜: 22.15 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[åˆå§‹çŠ¶æ€] GPUæ˜¾å­˜: å·²åˆ†é…=0.00GB, ä¿ç•™=0.00GB, å³°å€¼=0.00GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ä½¿ç”¨è®¾å¤‡: {device}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f'æ€»æ˜¾å­˜: {total_memory:.2f} GB')\n",
    "    \n",
    "    # é‡ç½®æ˜¾å­˜ç»Ÿè®¡\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    clear_gpu_memory()\n",
    "    print_gpu_memory(\"åˆå§‹çŠ¶æ€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset",
   "metadata": {
    "papermill": {
     "duration": 0.0089,
     "end_time": "2025-10-14T11:06:34.706042",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.697142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Patchæ•°æ®é›†\n",
    "\n",
    "### Patch-basedè®­ç»ƒåŸç†\n",
    "\n",
    "ä¼ ç»Ÿçš„è¶…åˆ†è¾¨ç‡è®­ç»ƒç›´æ¥ä½¿ç”¨å®Œæ•´çš„å¤§å›¾åƒï¼Œä½†4Kå›¾åƒ(4096Ã—4096)å¤ªå¤§ï¼Œæ— æ³•æ”¾å…¥GPUæ˜¾å­˜ã€‚\n",
    "\n",
    "**Patch-basedæ–¹æ³•**é€šè¿‡ä»¥ä¸‹ç­–ç•¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š\n",
    "\n",
    "1. **è®­ç»ƒæ—¶**: ä»å¤§å›¾ä¸­éšæœºè£å‰ªå°patches\n",
    "   - ä»4096Ã—4096å›¾åƒä¸­è£å‰ª512Ã—512çš„HR patch\n",
    "   - å°†HR patchä¸‹é‡‡æ ·åˆ°64Ã—64å¾—åˆ°LR patch\n",
    "   - æ¯å¼ å›¾å¯ä»¥æå–å¤šä¸ªpatchesï¼Œå¢åŠ æ•°æ®å¤šæ ·æ€§\n",
    "\n",
    "2. **ä¼˜åŠ¿**:\n",
    "   - æ˜¾å­˜å ç”¨å°ï¼ˆåªå¤„ç†512Ã—512è€Œé4096Ã—4096ï¼‰\n",
    "   - æ•°æ®å¢å¼ºä¸°å¯Œï¼ˆæ¯å¼ å›¾äº§ç”Ÿå¤šä¸ªpatchesï¼‰\n",
    "   - è®­ç»ƒæ›´å¿«ï¼ˆå°patchå‰å‘/åå‘ä¼ æ’­å¿«ï¼‰\n",
    "\n",
    "3. **æ¨ç†æ—¶**: ä½¿ç”¨æ»‘åŠ¨çª—å£æ‹¼æ¥\n",
    "   - å°†å¤§å›¾åˆ‡æˆoverlapping patches\n",
    "   - æ¯ä¸ªpatchç‹¬ç«‹è¶…åˆ†è¾¨ç‡\n",
    "   - æ‹¼æ¥æˆå®Œæ•´çš„å¤§å›¾\n",
    "\n",
    "### æ•°æ®å¢å¼º\n",
    "\n",
    "ä¸ºäº†æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼Œå¯¹æ¯ä¸ªpatchåº”ç”¨ï¼š\n",
    "- éšæœºæ°´å¹³ç¿»è½¬\n",
    "- éšæœºå‚ç›´ç¿»è½¬  \n",
    "- éšæœºæ—‹è½¬90Â°çš„å€æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dataset_class",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.725114Z",
     "iopub.status.busy": "2025-10-14T11:06:34.724912Z",
     "iopub.status.idle": "2025-10-14T11:06:34.736261Z",
     "shell.execute_reply": "2025-10-14T11:06:34.735333Z"
    },
    "papermill": {
     "duration": 0.023017,
     "end_time": "2025-10-14T11:06:34.738059",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.715042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PatchSRDataset(Dataset):\n",
    "    \"\"\"Patchæ•°æ®é›†\"\"\"\n",
    "    def __init__(self, hr_dir, lr_patch_size=64, scale_factor=8, \n",
    "                 patches_per_image=10, augment=True):\n",
    "        self.hr_dir = Path(hr_dir)\n",
    "        self.lr_patch_size = lr_patch_size\n",
    "        self.hr_patch_size = lr_patch_size * scale_factor\n",
    "        self.scale_factor = scale_factor\n",
    "        self.patches_per_image = patches_per_image\n",
    "        self.augment = augment\n",
    "        \n",
    "        self.hr_images = sorted(list(self.hr_dir.glob('*.png')))\n",
    "        \n",
    "        print(f\"\\næ•°æ®é›†é…ç½®:\")\n",
    "        print(f\"  å›¾åƒæ•°é‡: {len(self.hr_images)}\")\n",
    "        print(f\"  LR patch: {lr_patch_size}Ã—{lr_patch_size}\")\n",
    "        print(f\"  HR patch: {self.hr_patch_size}Ã—{self.hr_patch_size}\")\n",
    "        print(f\"  ç¼©æ”¾å€æ•°: {scale_factor}Ã—\")\n",
    "        print(f\"  æ€»patches: {len(self.hr_images) * patches_per_image}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.hr_images) * self.patches_per_image\n",
    "    \n",
    "    def augment_patch(self, lr, hr):\n",
    "        if random.random() > 0.5:\n",
    "            lr, hr = np.fliplr(lr), np.fliplr(hr)\n",
    "        if random.random() > 0.5:\n",
    "            lr, hr = np.flipud(lr), np.flipud(hr)\n",
    "        k = random.randint(0, 3)\n",
    "        if k > 0:\n",
    "            lr, hr = np.rot90(lr, k), np.rot90(hr, k)\n",
    "        return lr.copy(), hr.copy()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_idx = idx // self.patches_per_image\n",
    "        \n",
    "        hr_img = cv2.imread(str(self.hr_images[img_idx]))\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        h, w = hr_img.shape[:2]\n",
    "        max_y, max_x = h - self.hr_patch_size, w - self.hr_patch_size\n",
    "        \n",
    "        if max_y <= 0 or max_x <= 0:\n",
    "            hr_patch = cv2.resize(hr_img, (self.hr_patch_size, self.hr_patch_size))\n",
    "        else:\n",
    "            y, x = random.randint(0, max_y), random.randint(0, max_x)\n",
    "            hr_patch = hr_img[y:y+self.hr_patch_size, x:x+self.hr_patch_size]\n",
    "        \n",
    "        lr_patch = cv2.resize(hr_patch, (self.lr_patch_size, self.lr_patch_size), \n",
    "                             interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        if self.augment:\n",
    "            lr_patch, hr_patch = self.augment_patch(lr_patch, hr_patch)\n",
    "        \n",
    "        lr_tensor = torch.from_numpy(lr_patch.transpose(2, 0, 1)).float() / 255.0\n",
    "        hr_tensor = torch.from_numpy(hr_patch.transpose(2, 0, 1)).float() / 255.0\n",
    "        \n",
    "        return lr_tensor, hr_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model",
   "metadata": {
    "papermill": {
     "duration": 0.009236,
     "end_time": "2025-10-14T11:06:34.756628",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.747392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. è½»é‡çº§U-Netæ¨¡å‹æ¶æ„\n",
    "\n",
    "### æ¨¡å‹è®¾è®¡åŸåˆ™\n",
    "\n",
    "ä¸ºäº†åœ¨æœ‰é™æ˜¾å­˜ä¸‹è®­ç»ƒï¼Œæˆ‘ä»¬é‡‡ç”¨ä»¥ä¸‹è®¾è®¡ï¼š\n",
    "\n",
    "#### 1. **å‡å°‘é€šé“æ•°** \n",
    "- åŸºç¡€é€šé“æ•°è®¾ä¸º24ï¼ˆè€Œéå¸¸è§çš„64ï¼‰\n",
    "- æœ€æ·±å±‚é€šé“æ•°ä¸º96ï¼ˆè€Œé512ï¼‰\n",
    "- å‚æ•°é‡å‡å°‘çº¦75%\n",
    "\n",
    "#### 2. **ç§»é™¤BatchNorm**\n",
    "- BatchNorméœ€è¦é¢å¤–æ˜¾å­˜å­˜å‚¨running stats\n",
    "- å¯¹äºå°batch sizeï¼ŒBNæ•ˆæœä¸ä½³\n",
    "- ä½¿ç”¨æ®‹å·®è¿æ¥ä¿è¯è®­ç»ƒç¨³å®šæ€§\n",
    "\n",
    "#### 3. **æµ…å±‚ç¼–ç å™¨**\n",
    "- åªä¸‹é‡‡æ ·2æ¬¡ï¼ˆ64â†’32â†’16ï¼‰\n",
    "- é¿å…è¿‡å°çš„feature map\n",
    "- ä¿ç•™æ›´å¤šç©ºé—´ä¿¡æ¯\n",
    "\n",
    "#### 4. **æ¸è¿›å¼ä¸Šé‡‡æ ·**\n",
    "- ä»16Ã—16é€æ­¥ä¸Šé‡‡æ ·åˆ°512Ã—512\n",
    "- ä½¿ç”¨æœ€è¿‘é‚»æ’å€¼+å·ç§¯ï¼ˆæ¯”è½¬ç½®å·ç§¯çœæ˜¾å­˜ï¼‰\n",
    "- 5æ¬¡2Ã—ä¸Šé‡‡æ ·è¾¾åˆ°32Ã—æ”¾å¤§ï¼ˆ16â†’512ï¼‰\n",
    "\n",
    "### æ¶æ„æµç¨‹\n",
    "\n",
    "```\n",
    "è¾“å…¥: 64Ã—64Ã—3\n",
    "\n",
    "ç¼–ç å™¨:\n",
    "  64Ã—64Ã—3 â†’ Conv â†’ 64Ã—64Ã—24\n",
    "  64Ã—64Ã—24 â†’ DownConv â†’ 32Ã—32Ã—48\n",
    "  32Ã—32Ã—48 â†’ DownConv â†’ 16Ã—16Ã—96\n",
    "\n",
    "è§£ç å™¨ï¼ˆ8Ã—ä¸Šé‡‡æ ·ï¼‰:\n",
    "  16Ã—16Ã—96 â†’ Up â†’ 32Ã—32Ã—48\n",
    "  32Ã—32Ã—48 â†’ Up â†’ 64Ã—64Ã—24\n",
    "  64Ã—64Ã—24 â†’ Up â†’ 128Ã—128Ã—24\n",
    "  128Ã—128Ã—24 â†’ Up â†’ 256Ã—256Ã—24\n",
    "  256Ã—256Ã—24 â†’ Up â†’ 512Ã—512Ã—24\n",
    "  512Ã—512Ã—24 â†’ Conv1Ã—1 â†’ 512Ã—512Ã—3\n",
    "\n",
    "è¾“å‡º: 512Ã—512Ã—3\n",
    "```\n",
    "\n",
    "### å‚æ•°é‡ä¼°ç®—\n",
    "\n",
    "- ç¼–ç å™¨: ~50K parameters\n",
    "- è§£ç å™¨: ~200K parameters\n",
    "- **æ€»è®¡: ~250K parameters** (ç›¸æ¯”åŸç‰ˆUNetå‡å°‘95%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "model_def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.776059Z",
     "iopub.status.busy": "2025-10-14T11:06:34.775782Z",
     "iopub.status.idle": "2025-10-14T11:06:34.786052Z",
     "shell.execute_reply": "2025-10-14T11:06:34.784958Z"
    },
    "papermill": {
     "duration": 0.022436,
     "end_time": "2025-10-14T11:06:34.788087",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.765651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch, ch, 3, padding=1)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(x + self.conv(x))\n",
    "\n",
    "\n",
    "class TinyUNet8x(nn.Module):\n",
    "    \"\"\"è¶…è½»é‡8Ã—SRæ¨¡å‹ (64Ã—64 â†’ 512Ã—512)\n",
    "    \n",
    "    è®¾è®¡ï¼šæœ€å°åŒ–æ˜¾å­˜å ç”¨\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ch=24):  # å‡å°‘é€šé“æ•°åˆ°24\n",
    "        super().__init__()\n",
    "        \n",
    "        # ç¼–ç å™¨ (64 â†’ 32 â†’ 16)\n",
    "        self.inc = nn.Sequential(\n",
    "            nn.Conv2d(3, base_ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(base_ch, base_ch*2, 3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ResBlock(base_ch*2)\n",
    "        )\n",
    "        \n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(base_ch*2, base_ch*4, 3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ResBlock(base_ch*4)\n",
    "        )\n",
    "        \n",
    "        # ä¸Šé‡‡æ ·åˆ°8Ã— (16 â†’ 32 â†’ 64 â†’ 128 â†’ 256 â†’ 512)\n",
    "        self.up_blocks = nn.ModuleList([\n",
    "            self._make_up(base_ch*4, base_ch*2),  # 16â†’32\n",
    "            self._make_up(base_ch*2, base_ch),    # 32â†’64\n",
    "            self._make_up(base_ch, base_ch),      # 64â†’128\n",
    "            self._make_up(base_ch, base_ch),      # 128â†’256\n",
    "            self._make_up(base_ch, base_ch),      # 256â†’512\n",
    "        ])\n",
    "        \n",
    "        self.outc = nn.Conv2d(base_ch, 3, 1)\n",
    "    \n",
    "    def _make_up(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.inc(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        \n",
    "        for up in self.up_blocks:\n",
    "            x = up(x)\n",
    "        \n",
    "        return self.outc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {
    "papermill": {
     "duration": 0.00892,
     "end_time": "2025-10-14T11:06:34.806541",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.797621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. è®­ç»ƒé…ç½®ä¸è‡ªé€‚åº”ä¼˜åŒ–\n",
    "\n",
    "### æ ¸å¿ƒé…ç½®å‚æ•°\n",
    "\n",
    "#### Patchå¤§å°\n",
    "- **LR_PATCH_SIZE**: 64Ã—64 - ä½åˆ†è¾¨ç‡patchå¤§å°\n",
    "- **HR_PATCH_SIZE**: 512Ã—512 - é«˜åˆ†è¾¨ç‡patchå¤§å°  \n",
    "- **SCALE_FACTOR**: 8Ã— - æœ¬æ¨¡å‹çš„æ”¾å¤§å€æ•°\n",
    "\n",
    "#### è®­ç»ƒè¶…å‚æ•°\n",
    "- **BATCH_SIZE**: è‡ªåŠ¨æ£€æµ‹ - æ ¹æ®GPUæ˜¾å­˜è‡ªåŠ¨é€‰æ‹©\n",
    "- **GRADIENT_ACCUMULATION**: 2 - æ¢¯åº¦ç´¯ç§¯æ­¥æ•°\n",
    "  - æœ‰æ•ˆbatch = BATCH_SIZE Ã— GRADIENT_ACCUMULATION\n",
    "  - ä¾‹å¦‚: 2 Ã— 2 = 4 (æ¨¡æ‹Ÿbatch=4çš„æ•ˆæœ)\n",
    "- **LEARNING_RATE**: 1e-4 - å­¦ä¹ ç‡\n",
    "- **NUM_EPOCHS**: 50 - è®­ç»ƒè½®æ•°\n",
    "\n",
    "#### æ¨¡å‹é…ç½®\n",
    "- **BASE_CHANNELS**: 24 - åŸºç¡€é€šé“æ•°ï¼ˆè¶Šå°æ˜¾å­˜è¶Šå°‘ï¼‰\n",
    "- **PATCHES_PER_IMAGE**: 10 - æ¯å¼ å›¾æå–çš„patchæ•°é‡\n",
    "\n",
    "### ä¼˜åŒ–æŠ€æœ¯è¯¦è§£\n",
    "\n",
    "#### 1. æ¢¯åº¦ç´¯ç§¯ (Gradient Accumulation)\n",
    "\n",
    "**é—®é¢˜**: GPUæ˜¾å­˜æœ‰é™ï¼Œbatch sizeåªèƒ½è®¾ä¸º1æˆ–2ï¼Œè®­ç»ƒä¸ç¨³å®š\n",
    "\n",
    "**è§£å†³**: ç´¯ç§¯å¤šä¸ªmini-batchçš„æ¢¯åº¦å†æ›´æ–°\n",
    "\n",
    "```python\n",
    "for i, (input, target) in enumerate(loader):\n",
    "    loss = model(input, target) / accumulation_steps\n",
    "    loss.backward()  # ç´¯ç§¯æ¢¯åº¦\n",
    "    \n",
    "    if (i + 1) % accumulation_steps == 0:\n",
    "        optimizer.step()  # æ›´æ–°æƒé‡\n",
    "        optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦\n",
    "```\n",
    "\n",
    "**æ•ˆæœ**: batch=2, accumulation=2 â‰ˆ batch=4çš„è®­ç»ƒæ•ˆæœ\n",
    "\n",
    "#### 2. æ··åˆç²¾åº¦è®­ç»ƒ (Mixed Precision)\n",
    "\n",
    "**åŸç†**: \n",
    "- FP32: 32ä½æµ®ç‚¹æ•°ï¼ˆé«˜ç²¾åº¦ï¼Œé«˜æ˜¾å­˜ï¼‰\n",
    "- FP16: 16ä½æµ®ç‚¹æ•°ï¼ˆä½ç²¾åº¦ï¼Œä½æ˜¾å­˜ï¼‰\n",
    "- æ··åˆç²¾åº¦: å¤§éƒ¨åˆ†æ“ä½œç”¨FP16ï¼Œå…³é”®æ“ä½œç”¨FP32\n",
    "\n",
    "**æ˜¾å­˜èŠ‚çœ**: çº¦50%\n",
    "\n",
    "**ç²¾åº¦æŸå¤±**: å‡ ä¹æ²¡æœ‰ï¼ˆ<0.1%ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "config_params",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.826647Z",
     "iopub.status.busy": "2025-10-14T11:06:34.826204Z",
     "iopub.status.idle": "2025-10-14T11:06:34.836751Z",
     "shell.execute_reply": "2025-10-14T11:06:34.835558Z"
    },
    "papermill": {
     "duration": 0.023159,
     "end_time": "2025-10-14T11:06:34.838819",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.815660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== è®­ç»ƒé…ç½® ===\n",
      "Patch: 64Ã—64 â†’ 512Ã—512 (8Ã—)\n",
      "åˆå§‹Batch size: 4\n",
      "æ¢¯åº¦ç´¯ç§¯: 2 steps\n",
      "æœ‰æ•ˆBatch size: 8\n",
      "åŸºç¡€é€šé“æ•°: 24\n",
      "æ··åˆç²¾åº¦: True\n"
     ]
    }
   ],
   "source": [
    "# åŸºç¡€é…ç½®\n",
    "LR_PATCH_SIZE = 64\n",
    "SCALE_FACTOR = 8\n",
    "HR_PATCH_SIZE = LR_PATCH_SIZE * SCALE_FACTOR\n",
    "\n",
    "# è®­ç»ƒé…ç½®ï¼ˆä¼šè‡ªåŠ¨è°ƒæ•´ï¼‰\n",
    "INITIAL_BATCH_SIZE = 4  # ä»å°çš„batch sizeå¼€å§‹\n",
    "GRADIENT_ACCUMULATION = 2  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 50\n",
    "PATCHES_PER_IMAGE = 10\n",
    "\n",
    "BASE_CHANNELS = 24  # å‡å°‘åŸºç¡€é€šé“æ•°\n",
    "USE_MIXED_PRECISION = True\n",
    "TRAIN_SPLIT = 0.9\n",
    "\n",
    "HR_DIR = './dataset_4k/high_resolution'\n",
    "CHECKPOINT_DIR = Path('./checkpoints_debug')\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"\\n=== è®­ç»ƒé…ç½® ===\")\n",
    "print(f\"Patch: {LR_PATCH_SIZE}Ã—{LR_PATCH_SIZE} â†’ {HR_PATCH_SIZE}Ã—{HR_PATCH_SIZE} ({SCALE_FACTOR}Ã—)\")\n",
    "print(f\"åˆå§‹Batch size: {INITIAL_BATCH_SIZE}\")\n",
    "print(f\"æ¢¯åº¦ç´¯ç§¯: {GRADIENT_ACCUMULATION} steps\")\n",
    "print(f\"æœ‰æ•ˆBatch size: {INITIAL_BATCH_SIZE * GRADIENT_ACCUMULATION}\")\n",
    "print(f\"åŸºç¡€é€šé“æ•°: {BASE_CHANNELS}\")\n",
    "print(f\"æ··åˆç²¾åº¦: {USE_MIXED_PRECISION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_memory",
   "metadata": {
    "papermill": {
     "duration": 0.01011,
     "end_time": "2025-10-14T11:06:34.858910",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.848800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. æ˜¾å­˜æµ‹è¯•ä¸Batch Sizeè‡ªåŠ¨æ£€æµ‹\n",
    "\n",
    "### æµ‹è¯•ç›®çš„\n",
    "\n",
    "åœ¨å¼€å§‹è®­ç»ƒå‰ï¼Œè‡ªåŠ¨æµ‹è¯•ä¸åŒbatch sizeä¸‹çš„æ˜¾å­˜å ç”¨ï¼Œæ‰¾å‡ºæœ€å¤§å¯ç”¨batch sizeã€‚\n",
    "\n",
    "### æµ‹è¯•æµç¨‹\n",
    "\n",
    "```\n",
    "For batch_size in [1, 2, 4, 8]:\n",
    "    1. åˆ›å»ºéšæœºè¾“å…¥æ•°æ®\n",
    "    2. å‰å‘ä¼ æ’­ â†’ è®°å½•æ˜¾å­˜\n",
    "    3. è®¡ç®—æŸå¤±\n",
    "    4. åå‘ä¼ æ’­ â†’ è®°å½•æ˜¾å­˜\n",
    "    5. å¦‚æœOOMï¼Œåœæ­¢æµ‹è¯•\n",
    "```\n",
    "\n",
    "### è¾“å‡ºä¿¡æ¯\n",
    "\n",
    "å¯¹äºæ¯ä¸ªbatch sizeï¼Œæ˜¾ç¤ºï¼š\n",
    "- è¾“å…¥tensoræ˜¾å­˜å ç”¨\n",
    "- è¾“å‡ºtensoræ˜¾å­˜å ç”¨  \n",
    "- å‰å‘ä¼ æ’­åçš„æ€»æ˜¾å­˜\n",
    "- åå‘ä¼ æ’­åçš„å³°å€¼æ˜¾å­˜\n",
    "- æ˜¯å¦å¯ç”¨\n",
    "\n",
    "### è‡ªåŠ¨é€‰æ‹©ç­–ç•¥\n",
    "\n",
    "- é€‰æ‹©èƒ½æˆåŠŸè¿è¡Œçš„æœ€å¤§batch size\n",
    "- å¦‚æœæœ€å¤§batch sizeè¾ƒå°ï¼ˆ1-2ï¼‰ï¼Œå»ºè®®ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "memory_test",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.879830Z",
     "iopub.status.busy": "2025-10-14T11:06:34.879336Z",
     "iopub.status.idle": "2025-10-14T11:06:39.138138Z",
     "shell.execute_reply": "2025-10-14T11:06:39.137281Z"
    },
    "papermill": {
     "duration": 4.271404,
     "end_time": "2025-10-14T11:06:39.140001",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.868597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== æ˜¾å­˜æµ‹è¯• ===\n",
      "\n",
      "åˆ›å»ºæ¨¡å‹...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡å‹å‚æ•°: 327,915\n",
      "[æ¨¡å‹åŠ è½½å] GPUæ˜¾å­˜: å·²åˆ†é…=0.00GB, ä¿ç•™=0.00GB, å³°å€¼=0.00GB\n",
      "\n",
      "æµ‹è¯•å‰å‘ä¼ æ’­...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æµ‹è¯• batch_size=1:\n",
      "  è¾“å…¥æ˜¾å­˜: 0.0MB\n",
      "  ç›®æ ‡æ˜¾å­˜: 3.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2223134/2396609903.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=USE_MIXED_PRECISION):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[å‰å‘ä¼ æ’­ bs=1] GPUæ˜¾å­˜: å·²åˆ†é…=0.04GB, ä¿ç•™=0.11GB, å³°å€¼=0.08GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[åå‘ä¼ æ’­ bs=1] GPUæ˜¾å­˜: å·²åˆ†é…=0.01GB, ä¿ç•™=0.11GB, å³°å€¼=0.08GB\n",
      "  âœ“ batch_size=1 å¯ç”¨ (å³°å€¼æ˜¾å­˜: 0.08GB)\n",
      "\n",
      "æµ‹è¯• batch_size=2:\n",
      "  è¾“å…¥æ˜¾å­˜: 0.1MB\n",
      "  ç›®æ ‡æ˜¾å­˜: 6.0MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[å‰å‘ä¼ æ’­ bs=2] GPUæ˜¾å­˜: å·²åˆ†é…=0.08GB, ä¿ç•™=0.20GB, å³°å€¼=0.17GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[åå‘ä¼ æ’­ bs=2] GPUæ˜¾å­˜: å·²åˆ†é…=0.01GB, ä¿ç•™=0.20GB, å³°å€¼=0.17GB\n",
      "  âœ“ batch_size=2 å¯ç”¨ (å³°å€¼æ˜¾å­˜: 0.17GB)\n",
      "\n",
      "æµ‹è¯• batch_size=4:\n",
      "  è¾“å…¥æ˜¾å­˜: 0.2MB\n",
      "  ç›®æ ‡æ˜¾å­˜: 12.0MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[å‰å‘ä¼ æ’­ bs=4] GPUæ˜¾å­˜: å·²åˆ†é…=0.16GB, ä¿ç•™=0.40GB, å³°å€¼=0.33GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[åå‘ä¼ æ’­ bs=4] GPUæ˜¾å­˜: å·²åˆ†é…=0.02GB, ä¿ç•™=0.40GB, å³°å€¼=0.33GB\n",
      "  âœ“ batch_size=4 å¯ç”¨ (å³°å€¼æ˜¾å­˜: 0.33GB)\n",
      "\n",
      "æµ‹è¯• batch_size=8:\n",
      "  è¾“å…¥æ˜¾å­˜: 0.4MB\n",
      "  ç›®æ ‡æ˜¾å­˜: 24.0MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[å‰å‘ä¼ æ’­ bs=8] GPUæ˜¾å­˜: å·²åˆ†é…=0.32GB, ä¿ç•™=0.79GB, å³°å€¼=0.66GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[åå‘ä¼ æ’­ bs=8] GPUæ˜¾å­˜: å·²åˆ†é…=0.04GB, ä¿ç•™=0.98GB, å³°å€¼=0.66GB\n",
      "  âœ“ batch_size=8 å¯ç”¨ (å³°å€¼æ˜¾å­˜: 0.66GB)\n",
      "\n",
      "æ¨èbatch size: 8\n",
      "ä½¿ç”¨batch size: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== æ˜¾å­˜æµ‹è¯• ===\")\n",
    "print(\"\\nåˆ›å»ºæ¨¡å‹...\")\n",
    "test_model = TinyUNet8x(base_ch=BASE_CHANNELS).to(device)\n",
    "total_params = sum(p.numel() for p in test_model.parameters())\n",
    "print(f\"æ¨¡å‹å‚æ•°: {total_params:,}\")\n",
    "print_gpu_memory(\"æ¨¡å‹åŠ è½½å\")\n",
    "\n",
    "print(\"\\næµ‹è¯•å‰å‘ä¼ æ’­...\")\n",
    "test_batch_sizes = [1, 2, 4, 8]\n",
    "max_working_batch = 1\n",
    "\n",
    "for bs in test_batch_sizes:\n",
    "    try:\n",
    "        clear_gpu_memory()\n",
    "        test_lr = torch.randn(bs, 3, LR_PATCH_SIZE, LR_PATCH_SIZE).to(device)\n",
    "        test_hr = torch.randn(bs, 3, HR_PATCH_SIZE, HR_PATCH_SIZE).to(device)\n",
    "        \n",
    "        print(f\"\\næµ‹è¯• batch_size={bs}:\")\n",
    "        print(f\"  è¾“å…¥æ˜¾å­˜: {get_tensor_memory(test_lr):.1f}MB\")\n",
    "        print(f\"  ç›®æ ‡æ˜¾å­˜: {get_tensor_memory(test_hr):.1f}MB\")\n",
    "        \n",
    "        # æµ‹è¯•å‰å‘ä¼ æ’­\n",
    "        with autocast(enabled=USE_MIXED_PRECISION):\n",
    "            out = test_model(test_lr)\n",
    "            loss = nn.L1Loss()(out, test_hr)\n",
    "        \n",
    "        alloc, _, peak = print_gpu_memory(f\"å‰å‘ä¼ æ’­ bs={bs}\")\n",
    "        \n",
    "        # æµ‹è¯•åå‘ä¼ æ’­\n",
    "        loss.backward()\n",
    "        alloc, _, peak = print_gpu_memory(f\"åå‘ä¼ æ’­ bs={bs}\")\n",
    "        \n",
    "        max_working_batch = bs\n",
    "        print(f\"  âœ“ batch_size={bs} å¯ç”¨ (å³°å€¼æ˜¾å­˜: {peak:.2f}GB)\")\n",
    "        \n",
    "        del test_lr, test_hr, out, loss\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e):\n",
    "            print(f\"  âœ— batch_size={bs} OOM\")\n",
    "            break\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "clear_gpu_memory()\n",
    "del test_model\n",
    "\n",
    "print(f\"\\næ¨èbatch size: {max_working_batch}\")\n",
    "BATCH_SIZE = max_working_batch\n",
    "print(f\"ä½¿ç”¨batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading",
   "metadata": {
    "papermill": {
     "duration": 0.010729,
     "end_time": "2025-10-14T11:06:39.162742",
     "exception": false,
     "start_time": "2025-10-14T11:06:39.152013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. æ•°æ®åŠ è½½ä¸è®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†\n",
    "\n",
    "### æ•°æ®åŠ è½½é…ç½®\n",
    "\n",
    "ä½¿ç”¨PyTorchçš„DataLoaderåŠ è½½patchæ•°æ®é›†ï¼Œå…³é”®é…ç½®ï¼š\n",
    "\n",
    "#### DataLoaderå‚æ•°\n",
    "- **batch_size**: ä½¿ç”¨å‰é¢è‡ªåŠ¨æ£€æµ‹çš„æœ€å¤§batch size\n",
    "- **shuffle**: è®­ç»ƒé›†shuffle=Trueï¼Œæ‰“ä¹±é¡ºåºå¢å¼ºæ³›åŒ–\n",
    "- **num_workers**: è®¾ä¸º0ï¼ˆå•è¿›ç¨‹åŠ è½½ï¼‰\n",
    "  - å¤šè¿›ç¨‹åŠ è½½å¯èƒ½å¢åŠ æ˜¾å­˜å¼€é”€\n",
    "  - å¯¹äºå°patchï¼Œå•è¿›ç¨‹å·²è¶³å¤Ÿå¿«\n",
    "- **pin_memory**: Trueï¼ŒåŠ é€ŸGPUæ•°æ®ä¼ è¾“\n",
    "\n",
    "#### è®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†\n",
    "- **è®­ç»ƒé›†**: 90%çš„patches (ç”¨äºè®­ç»ƒæ¨¡å‹)\n",
    "- **éªŒè¯é›†**: 10%çš„patches (ç”¨äºç›‘æ§è¿‡æ‹Ÿåˆ)\n",
    "\n",
    "### æ•°æ®é‡è®¡ç®—\n",
    "\n",
    "å‡è®¾æœ‰300å¼ 4Kå›¾åƒï¼Œæ¯å¼ æå–10ä¸ªpatchesï¼š\n",
    "- æ€»patches: 300 Ã— 10 = 3000\n",
    "- è®­ç»ƒpatches: 3000 Ã— 0.9 = 2700\n",
    "- éªŒè¯patches: 3000 Ã— 0.1 = 300\n",
    "\n",
    "å¦‚æœbatch_size=2ï¼š\n",
    "- è®­ç»ƒbatches: 2700 / 2 = 1350\n",
    "- éªŒè¯batches: 300 / 2 = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "data_loader",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:39.184891Z",
     "iopub.status.busy": "2025-10-14T11:06:39.184665Z",
     "iopub.status.idle": "2025-10-14T11:06:39.193345Z",
     "shell.execute_reply": "2025-10-14T11:06:39.192452Z"
    },
    "papermill": {
     "duration": 0.021798,
     "end_time": "2025-10-14T11:06:39.195081",
     "exception": false,
     "start_time": "2025-10-14T11:06:39.173283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æ•°æ®é›†é…ç½®:\n",
      "  å›¾åƒæ•°é‡: 300\n",
      "  LR patch: 64Ã—64\n",
      "  HR patch: 512Ã—512\n",
      "  ç¼©æ”¾å€æ•°: 8Ã—\n",
      "  æ€»patches: 3000\n",
      "\n",
      "è®­ç»ƒé›†: 2700 patches, 338 batches\n",
      "éªŒè¯é›†: 300 patches, 38 batches\n"
     ]
    }
   ],
   "source": [
    "dataset = PatchSRDataset(\n",
    "    hr_dir=HR_DIR,\n",
    "    lr_patch_size=LR_PATCH_SIZE,\n",
    "    scale_factor=SCALE_FACTOR,\n",
    "    patches_per_image=PATCHES_PER_IMAGE,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "train_size = int(TRAIN_SPLIT * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=0, pin_memory=True  # num_workers=0æ›´ç¨³å®š\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nè®­ç»ƒé›†: {train_size} patches, {len(train_loader)} batches\")\n",
    "print(f\"éªŒè¯é›†: {val_size} patches, {len(val_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_init",
   "metadata": {
    "papermill": {
     "duration": 0.010791,
     "end_time": "2025-10-14T11:06:39.216827",
     "exception": false,
     "start_time": "2025-10-14T11:06:39.206036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. æ¨¡å‹ä¸ä¼˜åŒ–å™¨åˆå§‹åŒ–\n",
    "\n",
    "### è®­ç»ƒç»„ä»¶\n",
    "\n",
    "#### 1. æ¨¡å‹ (TinyUNet8x)\n",
    "- åŠ è½½åˆ°GPUè®¾å¤‡\n",
    "- åŸºç¡€é€šé“æ•°: 24\n",
    "- æ€»å‚æ•°é‡: ~250K\n",
    "\n",
    "#### 2. æŸå¤±å‡½æ•° (L1Loss)\n",
    "- ä¹Ÿç§°ä¸ºMAE (Mean Absolute Error)\n",
    "- æ¯”MSEæ›´å…³æ³¨å¤§è¯¯å·®ï¼Œé€‚åˆå›¾åƒè¶…åˆ†è¾¨ç‡\n",
    "- å…¬å¼: L = |é¢„æµ‹ - çœŸå®| çš„å¹³å‡å€¼\n",
    "\n",
    "#### 3. ä¼˜åŒ–å™¨ (Adam)\n",
    "- å­¦ä¹ ç‡: 1e-4 (0.0001)\n",
    "- Adamè‡ªé€‚åº”è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ ç‡\n",
    "- é€‚åˆå¤„ç†ç¨€ç–æ¢¯åº¦å’Œå™ªå£°æ•°æ®\n",
    "\n",
    "#### 4. å­¦ä¹ ç‡è°ƒåº¦å™¨ (CosineAnnealingLR)\n",
    "- ä½™å¼¦é€€ç«ç­–ç•¥\n",
    "- å­¦ä¹ ç‡ä»åˆå§‹å€¼é€æ¸é™ä½åˆ°æ¥è¿‘0\n",
    "- å‰æœŸå­¦ä¹ å¿«ï¼ŒåæœŸå¾®è°ƒ\n",
    "- å…¬å¼: lr = lr_min + (lr_max - lr_min) Ã— (1 + cos(Ï€ Ã— epoch / T_max)) / 2\n",
    "\n",
    "#### 5. æ¢¯åº¦ç¼©æ”¾å™¨ (GradScaler)\n",
    "- ä»…åœ¨æ··åˆç²¾åº¦è®­ç»ƒæ—¶ä½¿ç”¨\n",
    "- é˜²æ­¢FP16ä¸‹æ¢¯åº¦ä¸‹æº¢\n",
    "- è‡ªåŠ¨ç¼©æ”¾lossä»¥ä¿æŒæ¢¯åº¦æ•°å€¼ç¨³å®šæ€§\n",
    "\n",
    "### åˆå§‹åŒ–åæ˜¾å­˜\n",
    "\n",
    "æ¨¡å‹å‚æ•°å ç”¨çº¦50MBæ˜¾å­˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "init_model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:39.256454Z",
     "iopub.status.busy": "2025-10-14T11:06:39.256069Z",
     "iopub.status.idle": "2025-10-14T11:06:41.537435Z",
     "shell.execute_reply": "2025-10-14T11:06:41.536335Z"
    },
    "papermill": {
     "duration": 2.295403,
     "end_time": "2025-10-14T11:06:41.539531",
     "exception": false,
     "start_time": "2025-10-14T11:06:39.244128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "åˆå§‹åŒ–è®­ç»ƒç»„ä»¶...\n",
      "[æ¨¡å‹] GPUæ˜¾å­˜: å·²åˆ†é…=0.00GB, ä¿ç•™=0.00GB, å³°å€¼=0.66GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡å‹å‚æ•°: 327,915\n"
     ]
    }
   ],
   "source": [
    "clear_gpu_memory()\n",
    "print(\"\\nåˆå§‹åŒ–è®­ç»ƒç»„ä»¶...\")\n",
    "\n",
    "model = TinyUNet8x(base_ch=BASE_CHANNELS).to(device)\n",
    "print_gpu_memory(\"æ¨¡å‹\")\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "# å…¼å®¹æ–°æ—§PyTorchç‰ˆæœ¬çš„GradScaler\n",
    "if USE_MIXED_PRECISION:\n",
    "    try:\n",
    "        # æ–°ç‰ˆAPI (PyTorch >= 2.0)\n",
    "        scaler = torch.amp.GradScaler('cuda')\n",
    "    except AttributeError:\n",
    "        # æ—§ç‰ˆAPI (PyTorch < 2.0)\n",
    "        scaler = GradScaler()\n",
    "else:\n",
    "    scaler = None\n",
    "\n",
    "print(f\"æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_funcs",
   "metadata": {
    "papermill": {
     "duration": 0.011454,
     "end_time": "2025-10-14T11:06:41.562704",
     "exception": false,
     "start_time": "2025-10-14T11:06:41.551250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. è®­ç»ƒä¸éªŒè¯å‡½æ•°\n",
    "\n",
    "### train_epoch() - è®­ç»ƒä¸€ä¸ªepoch\n",
    "\n",
    "#### å‚æ•°è¯´æ˜\n",
    "- **grad_accum_steps**: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°\n",
    "- **verbose_memory**: æ˜¯å¦è¯¦ç»†æ‰“å°æ˜¾å­˜ä½¿ç”¨\n",
    "\n",
    "#### æ¢¯åº¦ç´¯ç§¯å®ç°\n",
    "\n",
    "```python\n",
    "optimizer.zero_grad()  # åˆå§‹åŒ–æ¢¯åº¦ä¸º0\n",
    "\n",
    "for i, (lr, hr) in enumerate(loader):\n",
    "    loss = criterion(out, hr) / grad_accum_steps  # é™¤ä»¥ç´¯ç§¯æ­¥æ•°\n",
    "    loss.backward()  # ç´¯ç§¯æ¢¯åº¦ï¼ˆä¸ç«‹å³æ›´æ–°æƒé‡ï¼‰\n",
    "\n",
    "    # æ¯grad_accum_stepsä¸ªbatchæ‰æ›´æ–°ä¸€æ¬¡\n",
    "    if (i + 1) % grad_accum_steps == 0:\n",
    "        optimizer.step()  # åº”ç”¨ç´¯ç§¯çš„æ¢¯åº¦\n",
    "        optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦\n",
    "```\n",
    "\n",
    "**æ•ˆæœ**:\n",
    "- batch_size=2, grad_accum=2 â†’ ç­‰æ•ˆäºbatch_size=4\n",
    "- æ˜¾å­˜å ç”¨ä»ç„¶åªæ˜¯batch_size=2çš„é‡\n",
    "\n",
    "#### æ··åˆç²¾åº¦è®­ç»ƒæµç¨‹\n",
    "\n",
    "```python\n",
    "with autocast(enabled=True):  # è‡ªåŠ¨è½¬æ¢ä¸ºFP16\n",
    "    out = model(lr)\n",
    "    loss = criterion(out, hr)\n",
    "\n",
    "scaler.scale(loss).backward()  # ç¼©æ”¾lossé˜²æ­¢æ¢¯åº¦ä¸‹æº¢\n",
    "scaler.step(optimizer)  # åº”ç”¨ç¼©æ”¾åçš„æ¢¯åº¦\n",
    "scaler.update()  # æ›´æ–°scalerçš„ç¼©æ”¾å› å­\n",
    "```\n",
    "\n",
    "#### è¿›åº¦æ˜¾ç¤º\n",
    "- tqdmè¿›åº¦æ¡æ˜¾ç¤ºè®­ç»ƒè¿›åº¦\n",
    "- å®æ—¶æ˜¾ç¤ºå½“å‰losså’ŒGPUæ˜¾å­˜å ç”¨\n",
    "- ç¬¬ä¸€ä¸ªepochæ˜¾ç¤ºè¯¦ç»†æ˜¾å­˜ä¿¡æ¯ï¼ˆæ¯100ä¸ªbatchï¼‰\n",
    "\n",
    "### validate() - éªŒè¯å‡½æ•°\n",
    "\n",
    "- ä½¿ç”¨torch.no_grad()ç¦ç”¨æ¢¯åº¦è®¡ç®—\n",
    "- èŠ‚çœæ˜¾å­˜å’Œè®¡ç®—æ—¶é—´\n",
    "- è¿”å›éªŒè¯é›†å¹³å‡loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "train_functions",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:41.587114Z",
     "iopub.status.busy": "2025-10-14T11:06:41.586662Z",
     "iopub.status.idle": "2025-10-14T11:06:41.600030Z",
     "shell.execute_reply": "2025-10-14T11:06:41.598927Z"
    },
    "papermill": {
     "duration": 0.027746,
     "end_time": "2025-10-14T11:06:41.602029",
     "exception": false,
     "start_time": "2025-10-14T11:06:41.574283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, scaler, device, \n",
    "                use_amp, grad_accum_steps=1, verbose_memory=False):\n",
    "    \"\"\"\n",
    "    è®­ç»ƒä¸€ä¸ªepochï¼Œå¸¦æ¢¯åº¦ç´¯ç§¯å’Œæ˜¾å­˜ç›‘æ§\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pbar = tqdm(loader, desc='è®­ç»ƒ')\n",
    "    for i, (lr, hr) in enumerate(pbar):\n",
    "        lr, hr = lr.to(device), hr.to(device)\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        if use_amp and scaler:\n",
    "            with autocast(enabled=True):  # ä¿®å¤ï¼šä¸ä½¿ç”¨device_typeå‚æ•°\n",
    "                out = model(lr)\n",
    "                loss = criterion(out, hr) / grad_accum_steps\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # æ¢¯åº¦ç´¯ç§¯\n",
    "            if (i + 1) % grad_accum_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "        else:\n",
    "            out = model(lr)\n",
    "            loss = criterion(out, hr) / grad_accum_steps\n",
    "            loss.backward()\n",
    "            \n",
    "            if (i + 1) % grad_accum_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item() * grad_accum_steps\n",
    "        \n",
    "        # æ˜¾ç¤ºæ˜¾å­˜ï¼ˆæ¯100ä¸ªbatchï¼‰\n",
    "        if verbose_memory and i % 100 == 0:\n",
    "            alloc, _, peak = print_gpu_memory(f\"Batch {i}\")\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item() * grad_accum_steps:.4f}',\n",
    "            'gpu': f'{torch.cuda.memory_allocated()/1024**3:.1f}GB'\n",
    "        })\n",
    "    \n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device, use_amp):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for lr, hr in tqdm(loader, desc='éªŒè¯'):\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "            \n",
    "            if use_amp:\n",
    "                with autocast(enabled=True):  # ä¿®å¤\n",
    "                    out = model(lr)\n",
    "                    loss = criterion(out, hr)\n",
    "            else:\n",
    "                out = model(lr)\n",
    "                loss = criterion(out, hr)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training",
   "metadata": {
    "papermill": {
     "duration": 0.011435,
     "end_time": "2025-10-14T11:06:41.625110",
     "exception": false,
     "start_time": "2025-10-14T11:06:41.613675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. ä¸»è®­ç»ƒå¾ªç¯\n",
    "\n",
    "### è®­ç»ƒæµç¨‹\n",
    "\n",
    "å¯¹äºæ¯ä¸ªepochï¼š\n",
    "\n",
    "1. **è®­ç»ƒé˜¶æ®µ**\n",
    "   - è°ƒç”¨train_epoch()åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒ\n",
    "   - ç¬¬ä¸€ä¸ªepochæ˜¾ç¤ºè¯¦ç»†æ˜¾å­˜ä¿¡æ¯\n",
    "   - è¿”å›å¹³å‡è®­ç»ƒæŸå¤±\n",
    "\n",
    "2. **éªŒè¯é˜¶æ®µ**\n",
    "   - è°ƒç”¨validate()åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°\n",
    "   - è¿”å›å¹³å‡éªŒè¯æŸå¤±\n",
    "\n",
    "3. **å­¦ä¹ ç‡è°ƒæ•´**\n",
    "   - scheduler.step()åº”ç”¨ä½™å¼¦é€€ç«\n",
    "\n",
    "4. **æ¨¡å‹ä¿å­˜ç­–ç•¥**\n",
    "   - **æœ€ä½³æ¨¡å‹**: éªŒè¯æŸå¤±æœ€ä½æ—¶ä¿å­˜ä¸º`best_model.pth`\n",
    "     - åŒ…å«æ¨¡å‹æƒé‡ã€ä¼˜åŒ–å™¨çŠ¶æ€ã€é…ç½®ä¿¡æ¯\n",
    "   - **å®šæœŸæ£€æŸ¥ç‚¹**: æ¯10ä¸ªepochä¿å­˜ä¸º`epoch_N.pth`\n",
    "     - ä¾¿äºæ¢å¤è®­ç»ƒæˆ–åˆ†æä¸åŒé˜¶æ®µçš„æ¨¡å‹\n",
    "\n",
    "5. **æ˜¾å­˜ç®¡ç†**\n",
    "   - æ¯5ä¸ªepochæ¸…ç†ä¸€æ¬¡GPUç¼“å­˜\n",
    "   - æ¯ä¸ªepochç»“æŸæ‰“å°æ˜¾å­˜ç»Ÿè®¡\n",
    "\n",
    "### OOMé”™è¯¯å¤„ç†\n",
    "\n",
    "å¦‚æœè®­ç»ƒä¸­å‡ºç°OOMé”™è¯¯ï¼Œè‡ªåŠ¨æ˜¾ç¤ºï¼š\n",
    "- å½“å‰æ˜¾å­˜ä½¿ç”¨æƒ…å†µ\n",
    "- ä¼˜åŒ–å»ºè®®ï¼š\n",
    "  1. å‡å°batch size\n",
    "  2. å¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°\n",
    "  3. å‡å°æ¨¡å‹é€šé“æ•°\n",
    "  4. å‡å°patch size\n",
    "\n",
    "### è¾“å‡ºä¿¡æ¯\n",
    "\n",
    "æ¯ä¸ªepochæ˜¾ç¤ºï¼š\n",
    "- è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŸå¤±\n",
    "- å½“å‰å­¦ä¹ ç‡\n",
    "- æ˜¾å­˜ä½¿ç”¨æƒ…å†µ\n",
    "- æ¨¡å‹ä¿å­˜çŠ¶æ€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "train_loop",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:41.649383Z",
     "iopub.status.busy": "2025-10-14T11:06:41.648939Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-10-14T11:06:41.636572",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "å¼€å§‹è®­ç»ƒ\n",
      "============================================================\n",
      "\n",
      "Epoch 1/50\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   0%|                                                                                            | 0/338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2223134/105892763.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):  # ä¿®å¤ï¼šä¸ä½¿ç”¨device_typeå‚æ•°\n",
      "\r",
      "è®­ç»ƒ:   0%|                                                                    | 0/338 [00:02<?, ?it/s, loss=0.1259, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   0%|â–                                                           | 1/338 [00:02<12:49,  2.28s/it, loss=0.1259, gpu=0.0GB]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 0] GPUæ˜¾å­˜: å·²åˆ†é…=0.04GB, ä¿ç•™=0.98GB, å³°å€¼=0.66GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   0%|â–                                                           | 1/338 [00:04<12:49,  2.28s/it, loss=0.3257, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   1%|â–                                                           | 2/338 [00:04<12:52,  2.30s/it, loss=0.3257, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   1%|â–                                                           | 2/338 [00:06<12:52,  2.30s/it, loss=0.2481, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   1%|â–Œ                                                           | 3/338 [00:06<12:23,  2.22s/it, loss=0.2481, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   1%|â–Œ                                                           | 3/338 [00:08<12:23,  2.22s/it, loss=0.1540, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   1%|â–‹                                                           | 4/338 [00:08<11:33,  2.08s/it, loss=0.1540, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   1%|â–‹                                                           | 4/338 [00:10<11:33,  2.08s/it, loss=0.1996, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   1%|â–‰                                                           | 5/338 [00:10<10:56,  1.97s/it, loss=0.1996, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   1%|â–‰                                                           | 5/338 [00:12<10:56,  1.97s/it, loss=0.1916, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   2%|â–ˆ                                                           | 6/338 [00:12<10:33,  1.91s/it, loss=0.1916, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   2%|â–ˆ                                                           | 6/338 [00:14<10:33,  1.91s/it, loss=0.1604, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   2%|â–ˆâ–                                                          | 7/338 [00:14<10:45,  1.95s/it, loss=0.1604, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   2%|â–ˆâ–                                                          | 7/338 [00:15<10:45,  1.95s/it, loss=0.1406, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   2%|â–ˆâ–                                                          | 8/338 [00:15<10:26,  1.90s/it, loss=0.1406, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   2%|â–ˆâ–                                                          | 8/338 [00:17<10:26,  1.90s/it, loss=0.2390, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   3%|â–ˆâ–Œ                                                          | 9/338 [00:17<10:13,  1.86s/it, loss=0.2390, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   3%|â–ˆâ–Œ                                                          | 9/338 [00:19<10:13,  1.86s/it, loss=0.2383, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   3%|â–ˆâ–‹                                                         | 10/338 [00:19<10:04,  1.84s/it, loss=0.2383, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   3%|â–ˆâ–‹                                                         | 10/338 [00:21<10:04,  1.84s/it, loss=0.2073, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   3%|â–ˆâ–‰                                                         | 11/338 [00:21<10:30,  1.93s/it, loss=0.2073, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   3%|â–ˆâ–‰                                                         | 11/338 [00:23<10:30,  1.93s/it, loss=0.1814, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   4%|â–ˆâ–ˆ                                                         | 12/338 [00:23<10:27,  1.92s/it, loss=0.1814, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   4%|â–ˆâ–ˆ                                                         | 12/338 [00:25<10:27,  1.92s/it, loss=0.1686, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   4%|â–ˆâ–ˆâ–                                                        | 13/338 [00:25<10:13,  1.89s/it, loss=0.1686, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   4%|â–ˆâ–ˆâ–                                                        | 13/338 [00:27<10:13,  1.89s/it, loss=0.2423, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   4%|â–ˆâ–ˆâ–                                                        | 14/338 [00:27<10:01,  1.86s/it, loss=0.2423, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   4%|â–ˆâ–ˆâ–                                                        | 14/338 [00:28<10:01,  1.86s/it, loss=0.3116, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   4%|â–ˆâ–ˆâ–Œ                                                        | 15/338 [00:28<09:52,  1.83s/it, loss=0.3116, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   4%|â–ˆâ–ˆâ–Œ                                                        | 15/338 [00:30<09:52,  1.83s/it, loss=0.1505, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   5%|â–ˆâ–ˆâ–Š                                                        | 16/338 [00:30<09:47,  1.83s/it, loss=0.1505, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   5%|â–ˆâ–ˆâ–Š                                                        | 16/338 [00:32<09:47,  1.83s/it, loss=0.1599, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   5%|â–ˆâ–ˆâ–‰                                                        | 17/338 [00:32<10:05,  1.89s/it, loss=0.1599, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   5%|â–ˆâ–ˆâ–‰                                                        | 17/338 [00:34<10:05,  1.89s/it, loss=0.1434, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   5%|â–ˆâ–ˆâ–ˆâ–                                                       | 18/338 [00:34<09:55,  1.86s/it, loss=0.1434, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   5%|â–ˆâ–ˆâ–ˆâ–                                                       | 18/338 [00:36<09:55,  1.86s/it, loss=0.3432, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   6%|â–ˆâ–ˆâ–ˆâ–                                                       | 19/338 [00:36<09:59,  1.88s/it, loss=0.3432, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   6%|â–ˆâ–ˆâ–ˆâ–                                                       | 19/338 [00:38<09:59,  1.88s/it, loss=0.1563, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   6%|â–ˆâ–ˆâ–ˆâ–                                                       | 20/338 [00:38<10:42,  2.02s/it, loss=0.1563, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   6%|â–ˆâ–ˆâ–ˆâ–                                                       | 20/338 [00:41<10:42,  2.02s/it, loss=0.2182, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   6%|â–ˆâ–ˆâ–ˆâ–‹                                                       | 21/338 [00:41<10:56,  2.07s/it, loss=0.2182, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   6%|â–ˆâ–ˆâ–ˆâ–‹                                                       | 21/338 [00:42<10:56,  2.07s/it, loss=0.2032, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   7%|â–ˆâ–ˆâ–ˆâ–Š                                                       | 22/338 [00:42<10:26,  1.98s/it, loss=0.2032, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   7%|â–ˆâ–ˆâ–ˆâ–Š                                                       | 22/338 [00:44<10:26,  1.98s/it, loss=0.2073, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   7%|â–ˆâ–ˆâ–ˆâ–ˆ                                                       | 23/338 [00:44<10:04,  1.92s/it, loss=0.2073, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   7%|â–ˆâ–ˆâ–ˆâ–ˆ                                                       | 23/338 [00:46<10:04,  1.92s/it, loss=0.3266, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 24/338 [00:46<09:57,  1.90s/it, loss=0.3266, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 24/338 [00:48<09:57,  1.90s/it, loss=0.1988, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 25/338 [00:48<09:45,  1.87s/it, loss=0.1988, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 25/338 [00:50<09:45,  1.87s/it, loss=0.1793, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                      | 26/338 [00:50<09:36,  1.85s/it, loss=0.1793, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                      | 26/338 [00:51<09:36,  1.85s/it, loss=0.2119, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                      | 27/338 [00:51<09:28,  1.83s/it, loss=0.2119, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                      | 27/338 [00:53<09:28,  1.83s/it, loss=0.2308, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                      | 28/338 [00:53<09:22,  1.81s/it, loss=0.2308, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                      | 28/338 [00:55<09:22,  1.81s/it, loss=0.1873, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                      | 29/338 [00:55<09:24,  1.83s/it, loss=0.1873, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                      | 29/338 [00:57<09:24,  1.83s/it, loss=0.1498, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 30/338 [00:57<09:57,  1.94s/it, loss=0.1498, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 30/338 [00:59<09:57,  1.94s/it, loss=0.2367, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 31/338 [00:59<09:41,  1.90s/it, loss=0.2367, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 31/338 [01:01<09:41,  1.90s/it, loss=0.2027, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                     | 32/338 [01:01<09:30,  1.87s/it, loss=0.2027, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                     | 32/338 [01:03<09:30,  1.87s/it, loss=0.1429, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                     | 33/338 [01:03<09:21,  1.84s/it, loss=0.1429, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                     | 33/338 [01:04<09:21,  1.84s/it, loss=0.1257, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                     | 34/338 [01:04<09:13,  1.82s/it, loss=0.1257, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                     | 34/338 [01:06<09:13,  1.82s/it, loss=0.2343, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                     | 35/338 [01:06<09:08,  1.81s/it, loss=0.2343, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                     | 35/338 [01:08<09:08,  1.81s/it, loss=0.2393, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 36/338 [01:08<09:04,  1.80s/it, loss=0.2393, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 36/338 [01:10<09:04,  1.80s/it, loss=0.2332, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 37/338 [01:10<09:00,  1.80s/it, loss=0.2332, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 37/338 [01:11<09:00,  1.80s/it, loss=0.1229, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                    | 38/338 [01:11<08:58,  1.80s/it, loss=0.1229, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                    | 38/338 [01:13<08:58,  1.80s/it, loss=0.1855, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                    | 39/338 [01:13<08:56,  1.80s/it, loss=0.1855, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                    | 39/338 [01:15<08:56,  1.80s/it, loss=0.1855, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                    | 40/338 [01:15<08:54,  1.79s/it, loss=0.1855, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                    | 40/338 [01:17<08:54,  1.79s/it, loss=0.1669, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 41/338 [01:17<08:57,  1.81s/it, loss=0.1669, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 41/338 [01:19<08:57,  1.81s/it, loss=0.1047, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 42/338 [01:19<09:37,  1.95s/it, loss=0.1047, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 42/338 [01:21<09:37,  1.95s/it, loss=0.1953, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                   | 43/338 [01:21<09:43,  1.98s/it, loss=0.1953, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                   | 43/338 [01:23<09:43,  1.98s/it, loss=0.2480, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                   | 44/338 [01:23<09:23,  1.92s/it, loss=0.2480, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                   | 44/338 [01:25<09:23,  1.92s/it, loss=0.2131, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                   | 45/338 [01:25<09:10,  1.88s/it, loss=0.2131, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                   | 45/338 [01:27<09:10,  1.88s/it, loss=0.0970, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                   | 46/338 [01:27<09:00,  1.85s/it, loss=0.0970, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                   | 46/338 [01:28<09:00,  1.85s/it, loss=0.1727, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                  | 47/338 [01:28<08:52,  1.83s/it, loss=0.1727, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                  | 47/338 [01:30<08:52,  1.83s/it, loss=0.1716, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                  | 48/338 [01:30<08:47,  1.82s/it, loss=0.1716, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "è®­ç»ƒ:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                  | 48/338 [01:32<08:47,  1.82s/it, loss=0.1026, gpu=0.0GB]"
     ]
    }
   ],
   "source": [
    "history = {'train_loss': [], 'val_loss': []}\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å¼€å§‹è®­ç»ƒ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # ç¬¬ä¸€ä¸ªepochæ˜¾ç¤ºè¯¦ç»†æ˜¾å­˜\n",
    "    verbose = (epoch == 0)\n",
    "    \n",
    "    try:\n",
    "        train_loss = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device,\n",
    "            USE_MIXED_PRECISION, GRADIENT_ACCUMULATION, verbose_memory=verbose\n",
    "        )\n",
    "        \n",
    "        val_loss = validate(model, val_loader, criterion, device, USE_MIXED_PRECISION)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"\\nè®­ç»ƒæŸå¤±: {train_loss:.6f}\")\n",
    "        print(f\"éªŒè¯æŸå¤±: {val_loss:.6f}\")\n",
    "        print(f\"å­¦ä¹ ç‡: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "        print_gpu_memory(f\"Epoch {epoch+1} ç»“æŸ\")\n",
    "        \n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'config': {\n",
    "                    'lr_patch': LR_PATCH_SIZE,\n",
    "                    'hr_patch': HR_PATCH_SIZE,\n",
    "                    'scale': SCALE_FACTOR,\n",
    "                    'base_ch': BASE_CHANNELS\n",
    "                }\n",
    "            }, CHECKPOINT_DIR / 'best_model.pth')\n",
    "            print(f\"âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹\")\n",
    "        \n",
    "        # å®šæœŸä¿å­˜\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), CHECKPOINT_DIR / f'epoch_{epoch+1}.pth')\n",
    "            print(f\"âœ“ ä¿å­˜æ£€æŸ¥ç‚¹\")\n",
    "        \n",
    "        # æ¸…ç†æ˜¾å­˜\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            clear_gpu_memory()\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e):\n",
    "            print(f\"\\n!!! OOMé”™è¯¯ !!!\")\n",
    "            print_gpu_memory(\"OOMæ—¶\")\n",
    "            print(\"\\nå»ºè®®:\")\n",
    "            print(f\"  1. å‡å°batch size (å½“å‰: {BATCH_SIZE})\")\n",
    "            print(f\"  2. å¢åŠ æ¢¯åº¦ç´¯ç§¯ (å½“å‰: {GRADIENT_ACCUMULATION})\")\n",
    "            print(f\"  3. å‡å°BASE_CHANNELS (å½“å‰: {BASE_CHANNELS})\")\n",
    "            print(f\"  4. å‡å°patch size (å½“å‰: {LR_PATCH_SIZE}â†’{HR_PATCH_SIZE})\")\n",
    "            raise e\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "print(f\"\\nè®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 11. è®­ç»ƒæ›²çº¿å¯è§†åŒ–\n",
    "\n",
    "### æŸå¤±æ›²çº¿å›¾\n",
    "\n",
    "ç»˜åˆ¶è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŸå¤±éšepochçš„å˜åŒ–ï¼š\n",
    "\n",
    "- **è“è‰²çº¿ (Training)**: è®­ç»ƒé›†æŸå¤±\n",
    "  - åº”è¯¥æŒç»­ä¸‹é™\n",
    "  - å¦‚æœä¸ä¸‹é™ï¼Œå­¦ä¹ ç‡å¯èƒ½å¤ªå°æˆ–æ¨¡å‹å®¹é‡ä¸è¶³\n",
    "\n",
    "- **æ©™è‰²çº¿ (Validation)**: éªŒè¯é›†æŸå¤±\n",
    "  - ç”¨äºåˆ¤æ–­æ˜¯å¦è¿‡æ‹Ÿåˆ\n",
    "  - å¦‚æœéªŒè¯æŸå¤±ä¸Šå‡è€Œè®­ç»ƒæŸå¤±ä¸‹é™ â†’ è¿‡æ‹Ÿåˆ\n",
    "\n",
    "### ç†æƒ³æ›²çº¿ç‰¹å¾\n",
    "\n",
    "âœ… **å¥åº·çš„è®­ç»ƒ**:\n",
    "- è®­ç»ƒå’ŒéªŒè¯æŸå¤±éƒ½æŒç»­ä¸‹é™\n",
    "- éªŒè¯æŸå¤±ç•¥é«˜äºè®­ç»ƒæŸå¤±\n",
    "- ä¸¤æ¡æ›²çº¿èµ°åŠ¿ç›¸ä¼¼\n",
    "\n",
    "âš ï¸ **è¿‡æ‹Ÿåˆè­¦å‘Š**:\n",
    "- è®­ç»ƒæŸå¤±å¾ˆä½ï¼ŒéªŒè¯æŸå¤±å¾ˆé«˜\n",
    "- éªŒè¯æŸå¤±å¼€å§‹ä¸Šå‡\n",
    "\n",
    "âš ï¸ **æ¬ æ‹Ÿåˆè­¦å‘Š**:\n",
    "- ä¸¤ä¸ªæŸå¤±éƒ½å¾ˆé«˜ä¸”ä¸ä¸‹é™\n",
    "- éœ€è¦å¢åŠ æ¨¡å‹å®¹é‡æˆ–è®­ç»ƒæ›´é•¿æ—¶é—´\n",
    "\n",
    "### ä¿å­˜\n",
    "\n",
    "æ›²çº¿å›¾è‡ªåŠ¨ä¿å­˜åˆ°`checkpoints_debug/curve.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_curve",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Training', marker='o')\n",
    "plt.plot(history['val_loss'], label='Validation', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'{SCALE_FACTOR}Ã— SR Training ({LR_PATCH_SIZE}â†’{HR_PATCH_SIZE})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(CHECKPOINT_DIR / 'curve.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 12. è®­ç»ƒæ€»ç»“æŠ¥å‘Š\n",
    "\n",
    "### æ€»ç»“å†…å®¹\n",
    "\n",
    "ç”Ÿæˆå®Œæ•´çš„è®­ç»ƒæ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š\n",
    "\n",
    "#### é…ç½®ä¿¡æ¯\n",
    "- Patchå¤§å°å’Œç¼©æ”¾å€æ•°\n",
    "- Batch sizeå’Œæ¢¯åº¦ç´¯ç§¯é…ç½®\n",
    "- æ¨¡å‹é€šé“æ•°å’Œå‚æ•°é‡\n",
    "\n",
    "#### æ˜¾å­˜ç»Ÿè®¡\n",
    "- è®­ç»ƒè¿‡ç¨‹ä¸­çš„å³°å€¼æ˜¾å­˜å ç”¨\n",
    "- ç”¨äºè¯„ä¼°æ˜¯å¦å¯ä»¥è¿›ä¸€æ­¥å¢åŠ batch sizeæˆ–æ¨¡å‹å¤§å°\n",
    "\n",
    "#### è®­ç»ƒç»“æœ\n",
    "- æœ€ä½³éªŒè¯æŸå¤±\n",
    "- æ€»è®­ç»ƒè½®æ•°\n",
    "- æ¨¡å‹ä¿å­˜è·¯å¾„\n",
    "\n",
    "### æ–‡ä»¶è¾“å‡º\n",
    "\n",
    "æ€»ç»“æŠ¥å‘Šä¼šï¼š\n",
    "1. æ‰“å°åˆ°æ§åˆ¶å°\n",
    "2. ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶: `checkpoints_debug/summary.txt`\n",
    "\n",
    "### åç»­æ­¥éª¤\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼š\n",
    "\n",
    "1. **åŠ è½½æœ€ä½³æ¨¡å‹**\n",
    "```python\n",
    "checkpoint = torch.load('checkpoints_debug/best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "```\n",
    "\n",
    "2. **æ¨ç†æµ‹è¯•**\n",
    "- ä½¿ç”¨æ»‘åŠ¨çª—å£å°†256Ã—256å›¾åƒè¶…åˆ†è¾¨ç‡åˆ°2048Ã—2048\n",
    "- å†ç”¨bicubicæ’å€¼æ”¾å¤§åˆ°4096Ã—4096\n",
    "\n",
    "3. **è´¨é‡è¯„ä¼°**\n",
    "- è®¡ç®—PSNR, SSIMæŒ‡æ ‡\n",
    "- ä¸bicubic/å…¶ä»–æ–¹æ³•å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary_code",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, _, peak_memory = print_gpu_memory(\"è®­ç»ƒç»“æŸ\")\n",
    "\n",
    "summary = f\"\"\"\n",
    "è®­ç»ƒæ€»ç»“\n",
    "{'='*60}\n",
    "\n",
    "é…ç½®:\n",
    "  Patch: {LR_PATCH_SIZE}Ã—{LR_PATCH_SIZE} â†’ {HR_PATCH_SIZE}Ã—{HR_PATCH_SIZE} ({SCALE_FACTOR}Ã—)\n",
    "  Batch size: {BATCH_SIZE}\n",
    "  æ¢¯åº¦ç´¯ç§¯: {GRADIENT_ACCUMULATION}\n",
    "  æœ‰æ•ˆbatch: {BATCH_SIZE * GRADIENT_ACCUMULATION}\n",
    "  åŸºç¡€é€šé“: {BASE_CHANNELS}\n",
    "  æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()):,}\n",
    "\n",
    "æ˜¾å­˜ä½¿ç”¨:\n",
    "  å³°å€¼æ˜¾å­˜: {peak_memory:.2f} GB\n",
    "\n",
    "ç»“æœ:\n",
    "  æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}\n",
    "  æ€»è®­ç»ƒè½®æ•°: {len(history['train_loss'])}\n",
    "\n",
    "æ¨¡å‹ä¿å­˜: {CHECKPOINT_DIR / 'best_model.pth'}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "with open(CHECKPOINT_DIR / 'summary.txt', 'w') as f:\n",
    "    f.write(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "train_patch_debug.ipynb",
   "output_path": "out_train_patch_debug_2025-10-14_1306.ipynb",
   "parameters": {},
   "start_time": "2025-10-14T11:06:28.251231",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}