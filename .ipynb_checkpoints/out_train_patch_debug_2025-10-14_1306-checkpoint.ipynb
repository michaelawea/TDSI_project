{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {
    "papermill": {
     "duration": 0.011609,
     "end_time": "2025-10-14T11:06:30.355921",
     "exception": false,
     "start_time": "2025-10-14T11:06:30.344312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Patch-based 4K Super-Resolution Training with Advanced Memory Debugging\n",
    "\n",
    "## 📋 概述\n",
    "\n",
    "本notebook实现了一个**基于patch的超分辨率训练系统**，专门设计用于在有限GPU显存下训练4K超分辨率模型。\n",
    "\n",
    "### 🎯 目标任务\n",
    "- **输入**: 256×256 低分辨率图像\n",
    "- **输出**: 4096×4096 高分辨率图像\n",
    "- **放大倍数**: 16× (分两阶段: 8× + 2×)\n",
    "\n",
    "### 🔑 核心特性\n",
    "\n",
    "#### 1. **Patch-based训练策略**\n",
    "- 不训练完整的大图像，而是训练小patch\n",
    "- LR patch: 64×64 → HR patch: 512×512 (8× scale)\n",
    "- 训练时显存占用极小 (~1-2GB)\n",
    "- 推理时使用滑动窗口拼接完整图像\n",
    "\n",
    "#### 2. **显存监控与调试系统** 🔍\n",
    "- 实时监控GPU显存使用情况\n",
    "- 自动测试最大可用batch size\n",
    "- 详细显示每个训练步骤的显存占用\n",
    "- OOM错误时给出具体优化建议\n",
    "\n",
    "#### 3. **自适应优化技术**\n",
    "- **混合精度训练** (FP16): 减少50%显存占用\n",
    "- **梯度累积**: 模拟更大batch size而不增加显存\n",
    "- **轻量级模型**: 最小化参数量和计算量\n",
    "- **自动batch size调整**: 根据GPU自动选择最优配置\n",
    "\n",
    "#### 4. **兼容性修复**\n",
    "- ✅ 修复PyTorch版本兼容性问题\n",
    "- ✅ 支持旧版和新版autocast API\n",
    "- ✅ 支持旧版和新版GradScaler API\n",
    "\n",
    "### 📊 显存占用估算\n",
    "\n",
    "| 组件 | 显存占用 (batch=1) | 显存占用 (batch=4) |\n",
    "|------|-------------------|-------------------|\n",
    "| 模型参数 | ~50 MB | ~50 MB |\n",
    "| 输入LR (64×64) | 0.05 MB | 0.2 MB |\n",
    "| 输出HR (512×512) | 3 MB | 12 MB |\n",
    "| 中间激活 | ~200 MB | ~800 MB |\n",
    "| 梯度 | ~50 MB | ~50 MB |\n",
    "| 优化器状态 | ~100 MB | ~100 MB |\n",
    "| **总计** | **~500 MB** | **~1.2 GB** |\n",
    "\n",
    "### 🚀 训练流程\n",
    "\n",
    "```\n",
    "Step 1: 数据准备\n",
    "  4096×4096 HR图像 → 随机裁剪512×512 patches\n",
    "  512×512 HR patch → 下采样得到64×64 LR patch\n",
    "\n",
    "Step 2: 训练8×模型\n",
    "  输入: 64×64 LR patch\n",
    "  输出: 512×512 SR patch\n",
    "  训练patches: 300张图 × 10 patches/图 = 3000 patches\n",
    "\n",
    "Step 3: 推理 (256×256 → 2048×2048)\n",
    "  256×256 → 切成4×4=16个64×64 patches\n",
    "  → 每个通过8×模型得到512×512\n",
    "  → 拼接成2048×2048\n",
    "\n",
    "Step 4: 最后放大 (2048×2048 → 4096×4096)\n",
    "  使用bicubic插值或轻量2×模型\n",
    "```\n",
    "\n",
    "### 📈 预期效果\n",
    "\n",
    "根据类似任务的经验：\n",
    "- **训练时间**: ~2-4小时 (50 epochs, RTX 3090)\n",
    "- **PSNR**: 28-32 dB\n",
    "- **SSIM**: 0.92-0.96\n",
    "- **显存占用**: <2GB\n",
    "\n",
    "### ⚙️ 配置说明\n",
    "\n",
    "可调整的关键参数：\n",
    "\n",
    "| 参数 | 默认值 | 作用 | 调整建议 |\n",
    "|------|-------|------|---------|\n",
    "| `LR_PATCH_SIZE` | 64 | LR patch大小 | 减小→降低显存 |\n",
    "| `SCALE_FACTOR` | 8 | 放大倍数 | 固定为8 |\n",
    "| `BATCH_SIZE` | 自动 | batch大小 | 自动测试 |\n",
    "| `BASE_CHANNELS` | 24 | 模型通道数 | 减小→降低显存 |\n",
    "| `GRADIENT_ACCUMULATION` | 2 | 梯度累积步数 | 增加→模拟大batch |\n",
    "\n",
    "---\n",
    "\n",
    "## 开始使用\n",
    "\n",
    "按顺序执行以下cells即可开始训练。系统会自动：\n",
    "1. 检测GPU显存\n",
    "2. 测试最优batch size\n",
    "3. 显示详细的显存使用情况\n",
    "4. 开始训练并保存最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:30.406268Z",
     "iopub.status.busy": "2025-10-14T11:06:30.405836Z",
     "iopub.status.idle": "2025-10-14T11:06:34.165737Z",
     "shell.execute_reply": "2025-10-14T11:06:34.164608Z"
    },
    "papermill": {
     "duration": 3.772242,
     "end_time": "2025-10-14T11:06:34.167867",
     "exception": false,
     "start_time": "2025-10-14T11:06:30.395625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utils",
   "metadata": {
    "papermill": {
     "duration": 0.008632,
     "end_time": "2025-10-14T11:06:34.186096",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.177464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. GPU显存监控工具\n",
    "\n",
    "这些工具函数用于实时监控和调试GPU显存使用情况。\n",
    "\n",
    "### 功能说明：\n",
    "\n",
    "1. **print_gpu_memory()**: 打印当前GPU显存状态\n",
    "   - `已分配`: PyTorch当前使用的显存\n",
    "   - `保留`: PyTorch从CUDA缓存池中保留的显存\n",
    "   - `峰值`: 训练过程中的最大显存占用\n",
    "\n",
    "2. **clear_gpu_memory()**: 清理GPU显存\n",
    "   - 调用Python垃圾回收\n",
    "   - 清空CUDA缓存\n",
    "   - 同步CUDA操作\n",
    "\n",
    "3. **get_tensor_memory()**: 计算单个tensor的显存占用\n",
    "   - 用于分析哪些tensor占用显存最多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "memory_utils",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.205785Z",
     "iopub.status.busy": "2025-10-14T11:06:34.205410Z",
     "iopub.status.idle": "2025-10-14T11:06:34.211922Z",
     "shell.execute_reply": "2025-10-14T11:06:34.210943Z"
    },
    "papermill": {
     "duration": 0.018984,
     "end_time": "2025-10-14T11:06:34.213905",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.194921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_gpu_memory(tag=\"\"):\n",
    "    \"\"\"打印当前GPU显存使用情况\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        max_allocated = torch.cuda.max_memory_allocated() / 1024**3\n",
    "        print(f\"[{tag}] GPU显存: 已分配={allocated:.2f}GB, 保留={reserved:.2f}GB, 峰值={max_allocated:.2f}GB\")\n",
    "        return allocated, reserved, max_allocated\n",
    "    return 0, 0, 0\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"清理GPU显存\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def get_tensor_memory(tensor):\n",
    "    \"\"\"获取tensor占用的显存(MB)\"\"\"\n",
    "    return tensor.element_size() * tensor.nelement() / 1024**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "device",
   "metadata": {
    "papermill": {
     "duration": 0.009049,
     "end_time": "2025-10-14T11:06:34.232258",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.223209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. 设备配置与初始状态检查\n",
    "\n",
    "检测可用的GPU设备，并显示初始显存状态。\n",
    "\n",
    "### 输出信息：\n",
    "- GPU型号\n",
    "- 总显存容量\n",
    "- 当前显存使用情况\n",
    "\n",
    "这一步会重置显存统计，确保后续的显存测试准确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "device_config",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.253013Z",
     "iopub.status.busy": "2025-10-14T11:06:34.252625Z",
     "iopub.status.idle": "2025-10-14T11:06:34.685121Z",
     "shell.execute_reply": "2025-10-14T11:06:34.684237Z"
    },
    "papermill": {
     "duration": 0.444584,
     "end_time": "2025-10-14T11:06:34.686968",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.242384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "GPU: Quadro RTX 6000\n",
      "总显存: 22.15 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[初始状态] GPU显存: 已分配=0.00GB, 保留=0.00GB, 峰值=0.00GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'使用设备: {device}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f'总显存: {total_memory:.2f} GB')\n",
    "    \n",
    "    # 重置显存统计\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    clear_gpu_memory()\n",
    "    print_gpu_memory(\"初始状态\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset",
   "metadata": {
    "papermill": {
     "duration": 0.0089,
     "end_time": "2025-10-14T11:06:34.706042",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.697142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Patch数据集\n",
    "\n",
    "### Patch-based训练原理\n",
    "\n",
    "传统的超分辨率训练直接使用完整的大图像，但4K图像(4096×4096)太大，无法放入GPU显存。\n",
    "\n",
    "**Patch-based方法**通过以下策略解决这个问题：\n",
    "\n",
    "1. **训练时**: 从大图中随机裁剪小patches\n",
    "   - 从4096×4096图像中裁剪512×512的HR patch\n",
    "   - 将HR patch下采样到64×64得到LR patch\n",
    "   - 每张图可以提取多个patches，增加数据多样性\n",
    "\n",
    "2. **优势**:\n",
    "   - 显存占用小（只处理512×512而非4096×4096）\n",
    "   - 数据增强丰富（每张图产生多个patches）\n",
    "   - 训练更快（小patch前向/反向传播快）\n",
    "\n",
    "3. **推理时**: 使用滑动窗口拼接\n",
    "   - 将大图切成overlapping patches\n",
    "   - 每个patch独立超分辨率\n",
    "   - 拼接成完整的大图\n",
    "\n",
    "### 数据增强\n",
    "\n",
    "为了提高模型泛化能力，对每个patch应用：\n",
    "- 随机水平翻转\n",
    "- 随机垂直翻转  \n",
    "- 随机旋转90°的倍数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dataset_class",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.725114Z",
     "iopub.status.busy": "2025-10-14T11:06:34.724912Z",
     "iopub.status.idle": "2025-10-14T11:06:34.736261Z",
     "shell.execute_reply": "2025-10-14T11:06:34.735333Z"
    },
    "papermill": {
     "duration": 0.023017,
     "end_time": "2025-10-14T11:06:34.738059",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.715042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PatchSRDataset(Dataset):\n",
    "    \"\"\"Patch数据集\"\"\"\n",
    "    def __init__(self, hr_dir, lr_patch_size=64, scale_factor=8, \n",
    "                 patches_per_image=10, augment=True):\n",
    "        self.hr_dir = Path(hr_dir)\n",
    "        self.lr_patch_size = lr_patch_size\n",
    "        self.hr_patch_size = lr_patch_size * scale_factor\n",
    "        self.scale_factor = scale_factor\n",
    "        self.patches_per_image = patches_per_image\n",
    "        self.augment = augment\n",
    "        \n",
    "        self.hr_images = sorted(list(self.hr_dir.glob('*.png')))\n",
    "        \n",
    "        print(f\"\\n数据集配置:\")\n",
    "        print(f\"  图像数量: {len(self.hr_images)}\")\n",
    "        print(f\"  LR patch: {lr_patch_size}×{lr_patch_size}\")\n",
    "        print(f\"  HR patch: {self.hr_patch_size}×{self.hr_patch_size}\")\n",
    "        print(f\"  缩放倍数: {scale_factor}×\")\n",
    "        print(f\"  总patches: {len(self.hr_images) * patches_per_image}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.hr_images) * self.patches_per_image\n",
    "    \n",
    "    def augment_patch(self, lr, hr):\n",
    "        if random.random() > 0.5:\n",
    "            lr, hr = np.fliplr(lr), np.fliplr(hr)\n",
    "        if random.random() > 0.5:\n",
    "            lr, hr = np.flipud(lr), np.flipud(hr)\n",
    "        k = random.randint(0, 3)\n",
    "        if k > 0:\n",
    "            lr, hr = np.rot90(lr, k), np.rot90(hr, k)\n",
    "        return lr.copy(), hr.copy()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_idx = idx // self.patches_per_image\n",
    "        \n",
    "        hr_img = cv2.imread(str(self.hr_images[img_idx]))\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        h, w = hr_img.shape[:2]\n",
    "        max_y, max_x = h - self.hr_patch_size, w - self.hr_patch_size\n",
    "        \n",
    "        if max_y <= 0 or max_x <= 0:\n",
    "            hr_patch = cv2.resize(hr_img, (self.hr_patch_size, self.hr_patch_size))\n",
    "        else:\n",
    "            y, x = random.randint(0, max_y), random.randint(0, max_x)\n",
    "            hr_patch = hr_img[y:y+self.hr_patch_size, x:x+self.hr_patch_size]\n",
    "        \n",
    "        lr_patch = cv2.resize(hr_patch, (self.lr_patch_size, self.lr_patch_size), \n",
    "                             interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        if self.augment:\n",
    "            lr_patch, hr_patch = self.augment_patch(lr_patch, hr_patch)\n",
    "        \n",
    "        lr_tensor = torch.from_numpy(lr_patch.transpose(2, 0, 1)).float() / 255.0\n",
    "        hr_tensor = torch.from_numpy(hr_patch.transpose(2, 0, 1)).float() / 255.0\n",
    "        \n",
    "        return lr_tensor, hr_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model",
   "metadata": {
    "papermill": {
     "duration": 0.009236,
     "end_time": "2025-10-14T11:06:34.756628",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.747392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. 轻量级U-Net模型架构\n",
    "\n",
    "### 模型设计原则\n",
    "\n",
    "为了在有限显存下训练，我们采用以下设计：\n",
    "\n",
    "#### 1. **减少通道数** \n",
    "- 基础通道数设为24（而非常见的64）\n",
    "- 最深层通道数为96（而非512）\n",
    "- 参数量减少约75%\n",
    "\n",
    "#### 2. **移除BatchNorm**\n",
    "- BatchNorm需要额外显存存储running stats\n",
    "- 对于小batch size，BN效果不佳\n",
    "- 使用残差连接保证训练稳定性\n",
    "\n",
    "#### 3. **浅层编码器**\n",
    "- 只下采样2次（64→32→16）\n",
    "- 避免过小的feature map\n",
    "- 保留更多空间信息\n",
    "\n",
    "#### 4. **渐进式上采样**\n",
    "- 从16×16逐步上采样到512×512\n",
    "- 使用最近邻插值+卷积（比转置卷积省显存）\n",
    "- 5次2×上采样达到32×放大（16→512）\n",
    "\n",
    "### 架构流程\n",
    "\n",
    "```\n",
    "输入: 64×64×3\n",
    "\n",
    "编码器:\n",
    "  64×64×3 → Conv → 64×64×24\n",
    "  64×64×24 → DownConv → 32×32×48\n",
    "  32×32×48 → DownConv → 16×16×96\n",
    "\n",
    "解码器（8×上采样）:\n",
    "  16×16×96 → Up → 32×32×48\n",
    "  32×32×48 → Up → 64×64×24\n",
    "  64×64×24 → Up → 128×128×24\n",
    "  128×128×24 → Up → 256×256×24\n",
    "  256×256×24 → Up → 512×512×24\n",
    "  512×512×24 → Conv1×1 → 512×512×3\n",
    "\n",
    "输出: 512×512×3\n",
    "```\n",
    "\n",
    "### 参数量估算\n",
    "\n",
    "- 编码器: ~50K parameters\n",
    "- 解码器: ~200K parameters\n",
    "- **总计: ~250K parameters** (相比原版UNet减少95%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "model_def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.776059Z",
     "iopub.status.busy": "2025-10-14T11:06:34.775782Z",
     "iopub.status.idle": "2025-10-14T11:06:34.786052Z",
     "shell.execute_reply": "2025-10-14T11:06:34.784958Z"
    },
    "papermill": {
     "duration": 0.022436,
     "end_time": "2025-10-14T11:06:34.788087",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.765651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch, ch, 3, padding=1)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(x + self.conv(x))\n",
    "\n",
    "\n",
    "class TinyUNet8x(nn.Module):\n",
    "    \"\"\"超轻量8×SR模型 (64×64 → 512×512)\n",
    "    \n",
    "    设计：最小化显存占用\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ch=24):  # 减少通道数到24\n",
    "        super().__init__()\n",
    "        \n",
    "        # 编码器 (64 → 32 → 16)\n",
    "        self.inc = nn.Sequential(\n",
    "            nn.Conv2d(3, base_ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(base_ch, base_ch*2, 3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ResBlock(base_ch*2)\n",
    "        )\n",
    "        \n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(base_ch*2, base_ch*4, 3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ResBlock(base_ch*4)\n",
    "        )\n",
    "        \n",
    "        # 上采样到8× (16 → 32 → 64 → 128 → 256 → 512)\n",
    "        self.up_blocks = nn.ModuleList([\n",
    "            self._make_up(base_ch*4, base_ch*2),  # 16→32\n",
    "            self._make_up(base_ch*2, base_ch),    # 32→64\n",
    "            self._make_up(base_ch, base_ch),      # 64→128\n",
    "            self._make_up(base_ch, base_ch),      # 128→256\n",
    "            self._make_up(base_ch, base_ch),      # 256→512\n",
    "        ])\n",
    "        \n",
    "        self.outc = nn.Conv2d(base_ch, 3, 1)\n",
    "    \n",
    "    def _make_up(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.inc(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        \n",
    "        for up in self.up_blocks:\n",
    "            x = up(x)\n",
    "        \n",
    "        return self.outc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {
    "papermill": {
     "duration": 0.00892,
     "end_time": "2025-10-14T11:06:34.806541",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.797621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. 训练配置与自适应优化\n",
    "\n",
    "### 核心配置参数\n",
    "\n",
    "#### Patch大小\n",
    "- **LR_PATCH_SIZE**: 64×64 - 低分辨率patch大小\n",
    "- **HR_PATCH_SIZE**: 512×512 - 高分辨率patch大小  \n",
    "- **SCALE_FACTOR**: 8× - 本模型的放大倍数\n",
    "\n",
    "#### 训练超参数\n",
    "- **BATCH_SIZE**: 自动检测 - 根据GPU显存自动选择\n",
    "- **GRADIENT_ACCUMULATION**: 2 - 梯度累积步数\n",
    "  - 有效batch = BATCH_SIZE × GRADIENT_ACCUMULATION\n",
    "  - 例如: 2 × 2 = 4 (模拟batch=4的效果)\n",
    "- **LEARNING_RATE**: 1e-4 - 学习率\n",
    "- **NUM_EPOCHS**: 50 - 训练轮数\n",
    "\n",
    "#### 模型配置\n",
    "- **BASE_CHANNELS**: 24 - 基础通道数（越小显存越少）\n",
    "- **PATCHES_PER_IMAGE**: 10 - 每张图提取的patch数量\n",
    "\n",
    "### 优化技术详解\n",
    "\n",
    "#### 1. 梯度累积 (Gradient Accumulation)\n",
    "\n",
    "**问题**: GPU显存有限，batch size只能设为1或2，训练不稳定\n",
    "\n",
    "**解决**: 累积多个mini-batch的梯度再更新\n",
    "\n",
    "```python\n",
    "for i, (input, target) in enumerate(loader):\n",
    "    loss = model(input, target) / accumulation_steps\n",
    "    loss.backward()  # 累积梯度\n",
    "    \n",
    "    if (i + 1) % accumulation_steps == 0:\n",
    "        optimizer.step()  # 更新权重\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "```\n",
    "\n",
    "**效果**: batch=2, accumulation=2 ≈ batch=4的训练效果\n",
    "\n",
    "#### 2. 混合精度训练 (Mixed Precision)\n",
    "\n",
    "**原理**: \n",
    "- FP32: 32位浮点数（高精度，高显存）\n",
    "- FP16: 16位浮点数（低精度，低显存）\n",
    "- 混合精度: 大部分操作用FP16，关键操作用FP32\n",
    "\n",
    "**显存节省**: 约50%\n",
    "\n",
    "**精度损失**: 几乎没有（<0.1%）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "config_params",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.826647Z",
     "iopub.status.busy": "2025-10-14T11:06:34.826204Z",
     "iopub.status.idle": "2025-10-14T11:06:34.836751Z",
     "shell.execute_reply": "2025-10-14T11:06:34.835558Z"
    },
    "papermill": {
     "duration": 0.023159,
     "end_time": "2025-10-14T11:06:34.838819",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.815660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 训练配置 ===\n",
      "Patch: 64×64 → 512×512 (8×)\n",
      "初始Batch size: 4\n",
      "梯度累积: 2 steps\n",
      "有效Batch size: 8\n",
      "基础通道数: 24\n",
      "混合精度: True\n"
     ]
    }
   ],
   "source": [
    "# 基础配置\n",
    "LR_PATCH_SIZE = 64\n",
    "SCALE_FACTOR = 8\n",
    "HR_PATCH_SIZE = LR_PATCH_SIZE * SCALE_FACTOR\n",
    "\n",
    "# 训练配置（会自动调整）\n",
    "INITIAL_BATCH_SIZE = 4  # 从小的batch size开始\n",
    "GRADIENT_ACCUMULATION = 2  # 梯度累积步数\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 50\n",
    "PATCHES_PER_IMAGE = 10\n",
    "\n",
    "BASE_CHANNELS = 24  # 减少基础通道数\n",
    "USE_MIXED_PRECISION = True\n",
    "TRAIN_SPLIT = 0.9\n",
    "\n",
    "HR_DIR = './dataset_4k/high_resolution'\n",
    "CHECKPOINT_DIR = Path('./checkpoints_debug')\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"\\n=== 训练配置 ===\")\n",
    "print(f\"Patch: {LR_PATCH_SIZE}×{LR_PATCH_SIZE} → {HR_PATCH_SIZE}×{HR_PATCH_SIZE} ({SCALE_FACTOR}×)\")\n",
    "print(f\"初始Batch size: {INITIAL_BATCH_SIZE}\")\n",
    "print(f\"梯度累积: {GRADIENT_ACCUMULATION} steps\")\n",
    "print(f\"有效Batch size: {INITIAL_BATCH_SIZE * GRADIENT_ACCUMULATION}\")\n",
    "print(f\"基础通道数: {BASE_CHANNELS}\")\n",
    "print(f\"混合精度: {USE_MIXED_PRECISION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_memory",
   "metadata": {
    "papermill": {
     "duration": 0.01011,
     "end_time": "2025-10-14T11:06:34.858910",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.848800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. 显存测试与Batch Size自动检测\n",
    "\n",
    "### 测试目的\n",
    "\n",
    "在开始训练前，自动测试不同batch size下的显存占用，找出最大可用batch size。\n",
    "\n",
    "### 测试流程\n",
    "\n",
    "```\n",
    "For batch_size in [1, 2, 4, 8]:\n",
    "    1. 创建随机输入数据\n",
    "    2. 前向传播 → 记录显存\n",
    "    3. 计算损失\n",
    "    4. 反向传播 → 记录显存\n",
    "    5. 如果OOM，停止测试\n",
    "```\n",
    "\n",
    "### 输出信息\n",
    "\n",
    "对于每个batch size，显示：\n",
    "- 输入tensor显存占用\n",
    "- 输出tensor显存占用  \n",
    "- 前向传播后的总显存\n",
    "- 反向传播后的峰值显存\n",
    "- 是否可用\n",
    "\n",
    "### 自动选择策略\n",
    "\n",
    "- 选择能成功运行的最大batch size\n",
    "- 如果最大batch size较小（1-2），建议使用梯度累积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "memory_test",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:34.879830Z",
     "iopub.status.busy": "2025-10-14T11:06:34.879336Z",
     "iopub.status.idle": "2025-10-14T11:06:39.138138Z",
     "shell.execute_reply": "2025-10-14T11:06:39.137281Z"
    },
    "papermill": {
     "duration": 4.271404,
     "end_time": "2025-10-14T11:06:39.140001",
     "exception": false,
     "start_time": "2025-10-14T11:06:34.868597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 显存测试 ===\n",
      "\n",
      "创建模型...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数: 327,915\n",
      "[模型加载后] GPU显存: 已分配=0.00GB, 保留=0.00GB, 峰值=0.00GB\n",
      "\n",
      "测试前向传播...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试 batch_size=1:\n",
      "  输入显存: 0.0MB\n",
      "  目标显存: 3.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2223134/2396609903.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=USE_MIXED_PRECISION):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[前向传播 bs=1] GPU显存: 已分配=0.04GB, 保留=0.11GB, 峰值=0.08GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[反向传播 bs=1] GPU显存: 已分配=0.01GB, 保留=0.11GB, 峰值=0.08GB\n",
      "  ✓ batch_size=1 可用 (峰值显存: 0.08GB)\n",
      "\n",
      "测试 batch_size=2:\n",
      "  输入显存: 0.1MB\n",
      "  目标显存: 6.0MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[前向传播 bs=2] GPU显存: 已分配=0.08GB, 保留=0.20GB, 峰值=0.17GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[反向传播 bs=2] GPU显存: 已分配=0.01GB, 保留=0.20GB, 峰值=0.17GB\n",
      "  ✓ batch_size=2 可用 (峰值显存: 0.17GB)\n",
      "\n",
      "测试 batch_size=4:\n",
      "  输入显存: 0.2MB\n",
      "  目标显存: 12.0MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[前向传播 bs=4] GPU显存: 已分配=0.16GB, 保留=0.40GB, 峰值=0.33GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[反向传播 bs=4] GPU显存: 已分配=0.02GB, 保留=0.40GB, 峰值=0.33GB\n",
      "  ✓ batch_size=4 可用 (峰值显存: 0.33GB)\n",
      "\n",
      "测试 batch_size=8:\n",
      "  输入显存: 0.4MB\n",
      "  目标显存: 24.0MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[前向传播 bs=8] GPU显存: 已分配=0.32GB, 保留=0.79GB, 峰值=0.66GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[反向传播 bs=8] GPU显存: 已分配=0.04GB, 保留=0.98GB, 峰值=0.66GB\n",
      "  ✓ batch_size=8 可用 (峰值显存: 0.66GB)\n",
      "\n",
      "推荐batch size: 8\n",
      "使用batch size: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 显存测试 ===\")\n",
    "print(\"\\n创建模型...\")\n",
    "test_model = TinyUNet8x(base_ch=BASE_CHANNELS).to(device)\n",
    "total_params = sum(p.numel() for p in test_model.parameters())\n",
    "print(f\"模型参数: {total_params:,}\")\n",
    "print_gpu_memory(\"模型加载后\")\n",
    "\n",
    "print(\"\\n测试前向传播...\")\n",
    "test_batch_sizes = [1, 2, 4, 8]\n",
    "max_working_batch = 1\n",
    "\n",
    "for bs in test_batch_sizes:\n",
    "    try:\n",
    "        clear_gpu_memory()\n",
    "        test_lr = torch.randn(bs, 3, LR_PATCH_SIZE, LR_PATCH_SIZE).to(device)\n",
    "        test_hr = torch.randn(bs, 3, HR_PATCH_SIZE, HR_PATCH_SIZE).to(device)\n",
    "        \n",
    "        print(f\"\\n测试 batch_size={bs}:\")\n",
    "        print(f\"  输入显存: {get_tensor_memory(test_lr):.1f}MB\")\n",
    "        print(f\"  目标显存: {get_tensor_memory(test_hr):.1f}MB\")\n",
    "        \n",
    "        # 测试前向传播\n",
    "        with autocast(enabled=USE_MIXED_PRECISION):\n",
    "            out = test_model(test_lr)\n",
    "            loss = nn.L1Loss()(out, test_hr)\n",
    "        \n",
    "        alloc, _, peak = print_gpu_memory(f\"前向传播 bs={bs}\")\n",
    "        \n",
    "        # 测试反向传播\n",
    "        loss.backward()\n",
    "        alloc, _, peak = print_gpu_memory(f\"反向传播 bs={bs}\")\n",
    "        \n",
    "        max_working_batch = bs\n",
    "        print(f\"  ✓ batch_size={bs} 可用 (峰值显存: {peak:.2f}GB)\")\n",
    "        \n",
    "        del test_lr, test_hr, out, loss\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e):\n",
    "            print(f\"  ✗ batch_size={bs} OOM\")\n",
    "            break\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "clear_gpu_memory()\n",
    "del test_model\n",
    "\n",
    "print(f\"\\n推荐batch size: {max_working_batch}\")\n",
    "BATCH_SIZE = max_working_batch\n",
    "print(f\"使用batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading",
   "metadata": {
    "papermill": {
     "duration": 0.010729,
     "end_time": "2025-10-14T11:06:39.162742",
     "exception": false,
     "start_time": "2025-10-14T11:06:39.152013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. 数据加载与训练/验证集划分\n",
    "\n",
    "### 数据加载配置\n",
    "\n",
    "使用PyTorch的DataLoader加载patch数据集，关键配置：\n",
    "\n",
    "#### DataLoader参数\n",
    "- **batch_size**: 使用前面自动检测的最大batch size\n",
    "- **shuffle**: 训练集shuffle=True，打乱顺序增强泛化\n",
    "- **num_workers**: 设为0（单进程加载）\n",
    "  - 多进程加载可能增加显存开销\n",
    "  - 对于小patch，单进程已足够快\n",
    "- **pin_memory**: True，加速GPU数据传输\n",
    "\n",
    "#### 训练/验证集划分\n",
    "- **训练集**: 90%的patches (用于训练模型)\n",
    "- **验证集**: 10%的patches (用于监控过拟合)\n",
    "\n",
    "### 数据量计算\n",
    "\n",
    "假设有300张4K图像，每张提取10个patches：\n",
    "- 总patches: 300 × 10 = 3000\n",
    "- 训练patches: 3000 × 0.9 = 2700\n",
    "- 验证patches: 3000 × 0.1 = 300\n",
    "\n",
    "如果batch_size=2：\n",
    "- 训练batches: 2700 / 2 = 1350\n",
    "- 验证batches: 300 / 2 = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "data_loader",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:39.184891Z",
     "iopub.status.busy": "2025-10-14T11:06:39.184665Z",
     "iopub.status.idle": "2025-10-14T11:06:39.193345Z",
     "shell.execute_reply": "2025-10-14T11:06:39.192452Z"
    },
    "papermill": {
     "duration": 0.021798,
     "end_time": "2025-10-14T11:06:39.195081",
     "exception": false,
     "start_time": "2025-10-14T11:06:39.173283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据集配置:\n",
      "  图像数量: 300\n",
      "  LR patch: 64×64\n",
      "  HR patch: 512×512\n",
      "  缩放倍数: 8×\n",
      "  总patches: 3000\n",
      "\n",
      "训练集: 2700 patches, 338 batches\n",
      "验证集: 300 patches, 38 batches\n"
     ]
    }
   ],
   "source": [
    "dataset = PatchSRDataset(\n",
    "    hr_dir=HR_DIR,\n",
    "    lr_patch_size=LR_PATCH_SIZE,\n",
    "    scale_factor=SCALE_FACTOR,\n",
    "    patches_per_image=PATCHES_PER_IMAGE,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "train_size = int(TRAIN_SPLIT * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=0, pin_memory=True  # num_workers=0更稳定\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\n训练集: {train_size} patches, {len(train_loader)} batches\")\n",
    "print(f\"验证集: {val_size} patches, {len(val_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_init",
   "metadata": {
    "papermill": {
     "duration": 0.010791,
     "end_time": "2025-10-14T11:06:39.216827",
     "exception": false,
     "start_time": "2025-10-14T11:06:39.206036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. 模型与优化器初始化\n",
    "\n",
    "### 训练组件\n",
    "\n",
    "#### 1. 模型 (TinyUNet8x)\n",
    "- 加载到GPU设备\n",
    "- 基础通道数: 24\n",
    "- 总参数量: ~250K\n",
    "\n",
    "#### 2. 损失函数 (L1Loss)\n",
    "- 也称为MAE (Mean Absolute Error)\n",
    "- 比MSE更关注大误差，适合图像超分辨率\n",
    "- 公式: L = |预测 - 真实| 的平均值\n",
    "\n",
    "#### 3. 优化器 (Adam)\n",
    "- 学习率: 1e-4 (0.0001)\n",
    "- Adam自适应调整每个参数的学习率\n",
    "- 适合处理稀疏梯度和噪声数据\n",
    "\n",
    "#### 4. 学习率调度器 (CosineAnnealingLR)\n",
    "- 余弦退火策略\n",
    "- 学习率从初始值逐渐降低到接近0\n",
    "- 前期学习快，后期微调\n",
    "- 公式: lr = lr_min + (lr_max - lr_min) × (1 + cos(π × epoch / T_max)) / 2\n",
    "\n",
    "#### 5. 梯度缩放器 (GradScaler)\n",
    "- 仅在混合精度训练时使用\n",
    "- 防止FP16下梯度下溢\n",
    "- 自动缩放loss以保持梯度数值稳定性\n",
    "\n",
    "### 初始化后显存\n",
    "\n",
    "模型参数占用约50MB显存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "init_model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:39.256454Z",
     "iopub.status.busy": "2025-10-14T11:06:39.256069Z",
     "iopub.status.idle": "2025-10-14T11:06:41.537435Z",
     "shell.execute_reply": "2025-10-14T11:06:41.536335Z"
    },
    "papermill": {
     "duration": 2.295403,
     "end_time": "2025-10-14T11:06:41.539531",
     "exception": false,
     "start_time": "2025-10-14T11:06:39.244128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "初始化训练组件...\n",
      "[模型] GPU显存: 已分配=0.00GB, 保留=0.00GB, 峰值=0.66GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数: 327,915\n"
     ]
    }
   ],
   "source": [
    "clear_gpu_memory()\n",
    "print(\"\\n初始化训练组件...\")\n",
    "\n",
    "model = TinyUNet8x(base_ch=BASE_CHANNELS).to(device)\n",
    "print_gpu_memory(\"模型\")\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "# 兼容新旧PyTorch版本的GradScaler\n",
    "if USE_MIXED_PRECISION:\n",
    "    try:\n",
    "        # 新版API (PyTorch >= 2.0)\n",
    "        scaler = torch.amp.GradScaler('cuda')\n",
    "    except AttributeError:\n",
    "        # 旧版API (PyTorch < 2.0)\n",
    "        scaler = GradScaler()\n",
    "else:\n",
    "    scaler = None\n",
    "\n",
    "print(f\"模型参数: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_funcs",
   "metadata": {
    "papermill": {
     "duration": 0.011454,
     "end_time": "2025-10-14T11:06:41.562704",
     "exception": false,
     "start_time": "2025-10-14T11:06:41.551250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. 训练与验证函数\n",
    "\n",
    "### train_epoch() - 训练一个epoch\n",
    "\n",
    "#### 参数说明\n",
    "- **grad_accum_steps**: 梯度累积步数\n",
    "- **verbose_memory**: 是否详细打印显存使用\n",
    "\n",
    "#### 梯度累积实现\n",
    "\n",
    "```python\n",
    "optimizer.zero_grad()  # 初始化梯度为0\n",
    "\n",
    "for i, (lr, hr) in enumerate(loader):\n",
    "    loss = criterion(out, hr) / grad_accum_steps  # 除以累积步数\n",
    "    loss.backward()  # 累积梯度（不立即更新权重）\n",
    "\n",
    "    # 每grad_accum_steps个batch才更新一次\n",
    "    if (i + 1) % grad_accum_steps == 0:\n",
    "        optimizer.step()  # 应用累积的梯度\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "```\n",
    "\n",
    "**效果**:\n",
    "- batch_size=2, grad_accum=2 → 等效于batch_size=4\n",
    "- 显存占用仍然只是batch_size=2的量\n",
    "\n",
    "#### 混合精度训练流程\n",
    "\n",
    "```python\n",
    "with autocast(enabled=True):  # 自动转换为FP16\n",
    "    out = model(lr)\n",
    "    loss = criterion(out, hr)\n",
    "\n",
    "scaler.scale(loss).backward()  # 缩放loss防止梯度下溢\n",
    "scaler.step(optimizer)  # 应用缩放后的梯度\n",
    "scaler.update()  # 更新scaler的缩放因子\n",
    "```\n",
    "\n",
    "#### 进度显示\n",
    "- tqdm进度条显示训练进度\n",
    "- 实时显示当前loss和GPU显存占用\n",
    "- 第一个epoch显示详细显存信息（每100个batch）\n",
    "\n",
    "### validate() - 验证函数\n",
    "\n",
    "- 使用torch.no_grad()禁用梯度计算\n",
    "- 节省显存和计算时间\n",
    "- 返回验证集平均loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "train_functions",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:41.587114Z",
     "iopub.status.busy": "2025-10-14T11:06:41.586662Z",
     "iopub.status.idle": "2025-10-14T11:06:41.600030Z",
     "shell.execute_reply": "2025-10-14T11:06:41.598927Z"
    },
    "papermill": {
     "duration": 0.027746,
     "end_time": "2025-10-14T11:06:41.602029",
     "exception": false,
     "start_time": "2025-10-14T11:06:41.574283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, scaler, device, \n",
    "                use_amp, grad_accum_steps=1, verbose_memory=False):\n",
    "    \"\"\"\n",
    "    训练一个epoch，带梯度累积和显存监控\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pbar = tqdm(loader, desc='训练')\n",
    "    for i, (lr, hr) in enumerate(pbar):\n",
    "        lr, hr = lr.to(device), hr.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        if use_amp and scaler:\n",
    "            with autocast(enabled=True):  # 修复：不使用device_type参数\n",
    "                out = model(lr)\n",
    "                loss = criterion(out, hr) / grad_accum_steps\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # 梯度累积\n",
    "            if (i + 1) % grad_accum_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "        else:\n",
    "            out = model(lr)\n",
    "            loss = criterion(out, hr) / grad_accum_steps\n",
    "            loss.backward()\n",
    "            \n",
    "            if (i + 1) % grad_accum_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item() * grad_accum_steps\n",
    "        \n",
    "        # 显示显存（每100个batch）\n",
    "        if verbose_memory and i % 100 == 0:\n",
    "            alloc, _, peak = print_gpu_memory(f\"Batch {i}\")\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item() * grad_accum_steps:.4f}',\n",
    "            'gpu': f'{torch.cuda.memory_allocated()/1024**3:.1f}GB'\n",
    "        })\n",
    "    \n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device, use_amp):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for lr, hr in tqdm(loader, desc='验证'):\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "            \n",
    "            if use_amp:\n",
    "                with autocast(enabled=True):  # 修复\n",
    "                    out = model(lr)\n",
    "                    loss = criterion(out, hr)\n",
    "            else:\n",
    "                out = model(lr)\n",
    "                loss = criterion(out, hr)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training",
   "metadata": {
    "papermill": {
     "duration": 0.011435,
     "end_time": "2025-10-14T11:06:41.625110",
     "exception": false,
     "start_time": "2025-10-14T11:06:41.613675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. 主训练循环\n",
    "\n",
    "### 训练流程\n",
    "\n",
    "对于每个epoch：\n",
    "\n",
    "1. **训练阶段**\n",
    "   - 调用train_epoch()在训练集上训练\n",
    "   - 第一个epoch显示详细显存信息\n",
    "   - 返回平均训练损失\n",
    "\n",
    "2. **验证阶段**\n",
    "   - 调用validate()在验证集上评估\n",
    "   - 返回平均验证损失\n",
    "\n",
    "3. **学习率调整**\n",
    "   - scheduler.step()应用余弦退火\n",
    "\n",
    "4. **模型保存策略**\n",
    "   - **最佳模型**: 验证损失最低时保存为`best_model.pth`\n",
    "     - 包含模型权重、优化器状态、配置信息\n",
    "   - **定期检查点**: 每10个epoch保存为`epoch_N.pth`\n",
    "     - 便于恢复训练或分析不同阶段的模型\n",
    "\n",
    "5. **显存管理**\n",
    "   - 每5个epoch清理一次GPU缓存\n",
    "   - 每个epoch结束打印显存统计\n",
    "\n",
    "### OOM错误处理\n",
    "\n",
    "如果训练中出现OOM错误，自动显示：\n",
    "- 当前显存使用情况\n",
    "- 优化建议：\n",
    "  1. 减小batch size\n",
    "  2. 增加梯度累积步数\n",
    "  3. 减小模型通道数\n",
    "  4. 减小patch size\n",
    "\n",
    "### 输出信息\n",
    "\n",
    "每个epoch显示：\n",
    "- 训练损失和验证损失\n",
    "- 当前学习率\n",
    "- 显存使用情况\n",
    "- 模型保存状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "train_loop",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T11:06:41.649383Z",
     "iopub.status.busy": "2025-10-14T11:06:41.648939Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-10-14T11:06:41.636572",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "开始训练\n",
      "============================================================\n",
      "\n",
      "Epoch 1/50\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   0%|                                                                                            | 0/338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2223134/105892763.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):  # 修复：不使用device_type参数\n",
      "\r",
      "训练:   0%|                                                                    | 0/338 [00:02<?, ?it/s, loss=0.1259, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   0%|▏                                                           | 1/338 [00:02<12:49,  2.28s/it, loss=0.1259, gpu=0.0GB]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 0] GPU显存: 已分配=0.04GB, 保留=0.98GB, 峰值=0.66GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   0%|▏                                                           | 1/338 [00:04<12:49,  2.28s/it, loss=0.3257, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   1%|▎                                                           | 2/338 [00:04<12:52,  2.30s/it, loss=0.3257, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   1%|▎                                                           | 2/338 [00:06<12:52,  2.30s/it, loss=0.2481, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   1%|▌                                                           | 3/338 [00:06<12:23,  2.22s/it, loss=0.2481, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   1%|▌                                                           | 3/338 [00:08<12:23,  2.22s/it, loss=0.1540, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   1%|▋                                                           | 4/338 [00:08<11:33,  2.08s/it, loss=0.1540, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   1%|▋                                                           | 4/338 [00:10<11:33,  2.08s/it, loss=0.1996, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   1%|▉                                                           | 5/338 [00:10<10:56,  1.97s/it, loss=0.1996, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   1%|▉                                                           | 5/338 [00:12<10:56,  1.97s/it, loss=0.1916, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   2%|█                                                           | 6/338 [00:12<10:33,  1.91s/it, loss=0.1916, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   2%|█                                                           | 6/338 [00:14<10:33,  1.91s/it, loss=0.1604, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   2%|█▏                                                          | 7/338 [00:14<10:45,  1.95s/it, loss=0.1604, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   2%|█▏                                                          | 7/338 [00:15<10:45,  1.95s/it, loss=0.1406, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   2%|█▍                                                          | 8/338 [00:15<10:26,  1.90s/it, loss=0.1406, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   2%|█▍                                                          | 8/338 [00:17<10:26,  1.90s/it, loss=0.2390, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   3%|█▌                                                          | 9/338 [00:17<10:13,  1.86s/it, loss=0.2390, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   3%|█▌                                                          | 9/338 [00:19<10:13,  1.86s/it, loss=0.2383, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   3%|█▋                                                         | 10/338 [00:19<10:04,  1.84s/it, loss=0.2383, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   3%|█▋                                                         | 10/338 [00:21<10:04,  1.84s/it, loss=0.2073, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   3%|█▉                                                         | 11/338 [00:21<10:30,  1.93s/it, loss=0.2073, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   3%|█▉                                                         | 11/338 [00:23<10:30,  1.93s/it, loss=0.1814, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   4%|██                                                         | 12/338 [00:23<10:27,  1.92s/it, loss=0.1814, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   4%|██                                                         | 12/338 [00:25<10:27,  1.92s/it, loss=0.1686, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   4%|██▎                                                        | 13/338 [00:25<10:13,  1.89s/it, loss=0.1686, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   4%|██▎                                                        | 13/338 [00:27<10:13,  1.89s/it, loss=0.2423, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   4%|██▍                                                        | 14/338 [00:27<10:01,  1.86s/it, loss=0.2423, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   4%|██▍                                                        | 14/338 [00:28<10:01,  1.86s/it, loss=0.3116, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   4%|██▌                                                        | 15/338 [00:28<09:52,  1.83s/it, loss=0.3116, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   4%|██▌                                                        | 15/338 [00:30<09:52,  1.83s/it, loss=0.1505, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   5%|██▊                                                        | 16/338 [00:30<09:47,  1.83s/it, loss=0.1505, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   5%|██▊                                                        | 16/338 [00:32<09:47,  1.83s/it, loss=0.1599, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   5%|██▉                                                        | 17/338 [00:32<10:05,  1.89s/it, loss=0.1599, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   5%|██▉                                                        | 17/338 [00:34<10:05,  1.89s/it, loss=0.1434, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   5%|███▏                                                       | 18/338 [00:34<09:55,  1.86s/it, loss=0.1434, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   5%|███▏                                                       | 18/338 [00:36<09:55,  1.86s/it, loss=0.3432, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   6%|███▎                                                       | 19/338 [00:36<09:59,  1.88s/it, loss=0.3432, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   6%|███▎                                                       | 19/338 [00:38<09:59,  1.88s/it, loss=0.1563, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   6%|███▍                                                       | 20/338 [00:38<10:42,  2.02s/it, loss=0.1563, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   6%|███▍                                                       | 20/338 [00:41<10:42,  2.02s/it, loss=0.2182, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   6%|███▋                                                       | 21/338 [00:41<10:56,  2.07s/it, loss=0.2182, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   6%|███▋                                                       | 21/338 [00:42<10:56,  2.07s/it, loss=0.2032, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   7%|███▊                                                       | 22/338 [00:42<10:26,  1.98s/it, loss=0.2032, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   7%|███▊                                                       | 22/338 [00:44<10:26,  1.98s/it, loss=0.2073, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   7%|████                                                       | 23/338 [00:44<10:04,  1.92s/it, loss=0.2073, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   7%|████                                                       | 23/338 [00:46<10:04,  1.92s/it, loss=0.3266, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   7%|████▏                                                      | 24/338 [00:46<09:57,  1.90s/it, loss=0.3266, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   7%|████▏                                                      | 24/338 [00:48<09:57,  1.90s/it, loss=0.1988, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   7%|████▎                                                      | 25/338 [00:48<09:45,  1.87s/it, loss=0.1988, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   7%|████▎                                                      | 25/338 [00:50<09:45,  1.87s/it, loss=0.1793, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   8%|████▌                                                      | 26/338 [00:50<09:36,  1.85s/it, loss=0.1793, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   8%|████▌                                                      | 26/338 [00:51<09:36,  1.85s/it, loss=0.2119, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   8%|████▋                                                      | 27/338 [00:51<09:28,  1.83s/it, loss=0.2119, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   8%|████▋                                                      | 27/338 [00:53<09:28,  1.83s/it, loss=0.2308, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   8%|████▉                                                      | 28/338 [00:53<09:22,  1.81s/it, loss=0.2308, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   8%|████▉                                                      | 28/338 [00:55<09:22,  1.81s/it, loss=0.1873, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   9%|█████                                                      | 29/338 [00:55<09:24,  1.83s/it, loss=0.1873, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   9%|█████                                                      | 29/338 [00:57<09:24,  1.83s/it, loss=0.1498, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   9%|█████▏                                                     | 30/338 [00:57<09:57,  1.94s/it, loss=0.1498, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   9%|█████▏                                                     | 30/338 [00:59<09:57,  1.94s/it, loss=0.2367, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   9%|█████▍                                                     | 31/338 [00:59<09:41,  1.90s/it, loss=0.2367, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   9%|█████▍                                                     | 31/338 [01:01<09:41,  1.90s/it, loss=0.2027, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   9%|█████▌                                                     | 32/338 [01:01<09:30,  1.87s/it, loss=0.2027, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:   9%|█████▌                                                     | 32/338 [01:03<09:30,  1.87s/it, loss=0.1429, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  10%|█████▊                                                     | 33/338 [01:03<09:21,  1.84s/it, loss=0.1429, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  10%|█████▊                                                     | 33/338 [01:04<09:21,  1.84s/it, loss=0.1257, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  10%|█████▉                                                     | 34/338 [01:04<09:13,  1.82s/it, loss=0.1257, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  10%|█████▉                                                     | 34/338 [01:06<09:13,  1.82s/it, loss=0.2343, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  10%|██████                                                     | 35/338 [01:06<09:08,  1.81s/it, loss=0.2343, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  10%|██████                                                     | 35/338 [01:08<09:08,  1.81s/it, loss=0.2393, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  11%|██████▎                                                    | 36/338 [01:08<09:04,  1.80s/it, loss=0.2393, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  11%|██████▎                                                    | 36/338 [01:10<09:04,  1.80s/it, loss=0.2332, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  11%|██████▍                                                    | 37/338 [01:10<09:00,  1.80s/it, loss=0.2332, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  11%|██████▍                                                    | 37/338 [01:11<09:00,  1.80s/it, loss=0.1229, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  11%|██████▋                                                    | 38/338 [01:11<08:58,  1.80s/it, loss=0.1229, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  11%|██████▋                                                    | 38/338 [01:13<08:58,  1.80s/it, loss=0.1855, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  12%|██████▊                                                    | 39/338 [01:13<08:56,  1.80s/it, loss=0.1855, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  12%|██████▊                                                    | 39/338 [01:15<08:56,  1.80s/it, loss=0.1855, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  12%|██████▉                                                    | 40/338 [01:15<08:54,  1.79s/it, loss=0.1855, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  12%|██████▉                                                    | 40/338 [01:17<08:54,  1.79s/it, loss=0.1669, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  12%|███████▏                                                   | 41/338 [01:17<08:57,  1.81s/it, loss=0.1669, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  12%|███████▏                                                   | 41/338 [01:19<08:57,  1.81s/it, loss=0.1047, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  12%|███████▎                                                   | 42/338 [01:19<09:37,  1.95s/it, loss=0.1047, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  12%|███████▎                                                   | 42/338 [01:21<09:37,  1.95s/it, loss=0.1953, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  13%|███████▌                                                   | 43/338 [01:21<09:43,  1.98s/it, loss=0.1953, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  13%|███████▌                                                   | 43/338 [01:23<09:43,  1.98s/it, loss=0.2480, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  13%|███████▋                                                   | 44/338 [01:23<09:23,  1.92s/it, loss=0.2480, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  13%|███████▋                                                   | 44/338 [01:25<09:23,  1.92s/it, loss=0.2131, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  13%|███████▊                                                   | 45/338 [01:25<09:10,  1.88s/it, loss=0.2131, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  13%|███████▊                                                   | 45/338 [01:27<09:10,  1.88s/it, loss=0.0970, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  14%|████████                                                   | 46/338 [01:27<09:00,  1.85s/it, loss=0.0970, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  14%|████████                                                   | 46/338 [01:28<09:00,  1.85s/it, loss=0.1727, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  14%|████████▏                                                  | 47/338 [01:28<08:52,  1.83s/it, loss=0.1727, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  14%|████████▏                                                  | 47/338 [01:30<08:52,  1.83s/it, loss=0.1716, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  14%|████████▍                                                  | 48/338 [01:30<08:47,  1.82s/it, loss=0.1716, gpu=0.0GB]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "训练:  14%|████████▍                                                  | 48/338 [01:32<08:47,  1.82s/it, loss=0.1026, gpu=0.0GB]"
     ]
    }
   ],
   "source": [
    "history = {'train_loss': [], 'val_loss': []}\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"开始训练\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 第一个epoch显示详细显存\n",
    "    verbose = (epoch == 0)\n",
    "    \n",
    "    try:\n",
    "        train_loss = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device,\n",
    "            USE_MIXED_PRECISION, GRADIENT_ACCUMULATION, verbose_memory=verbose\n",
    "        )\n",
    "        \n",
    "        val_loss = validate(model, val_loader, criterion, device, USE_MIXED_PRECISION)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"\\n训练损失: {train_loss:.6f}\")\n",
    "        print(f\"验证损失: {val_loss:.6f}\")\n",
    "        print(f\"学习率: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "        print_gpu_memory(f\"Epoch {epoch+1} 结束\")\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'config': {\n",
    "                    'lr_patch': LR_PATCH_SIZE,\n",
    "                    'hr_patch': HR_PATCH_SIZE,\n",
    "                    'scale': SCALE_FACTOR,\n",
    "                    'base_ch': BASE_CHANNELS\n",
    "                }\n",
    "            }, CHECKPOINT_DIR / 'best_model.pth')\n",
    "            print(f\"✓ 保存最佳模型\")\n",
    "        \n",
    "        # 定期保存\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), CHECKPOINT_DIR / f'epoch_{epoch+1}.pth')\n",
    "            print(f\"✓ 保存检查点\")\n",
    "        \n",
    "        # 清理显存\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            clear_gpu_memory()\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e):\n",
    "            print(f\"\\n!!! OOM错误 !!!\")\n",
    "            print_gpu_memory(\"OOM时\")\n",
    "            print(\"\\n建议:\")\n",
    "            print(f\"  1. 减小batch size (当前: {BATCH_SIZE})\")\n",
    "            print(f\"  2. 增加梯度累积 (当前: {GRADIENT_ACCUMULATION})\")\n",
    "            print(f\"  3. 减小BASE_CHANNELS (当前: {BASE_CHANNELS})\")\n",
    "            print(f\"  4. 减小patch size (当前: {LR_PATCH_SIZE}→{HR_PATCH_SIZE})\")\n",
    "            raise e\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "print(f\"\\n训练完成！最佳验证损失: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 11. 训练曲线可视化\n",
    "\n",
    "### 损失曲线图\n",
    "\n",
    "绘制训练损失和验证损失随epoch的变化：\n",
    "\n",
    "- **蓝色线 (Training)**: 训练集损失\n",
    "  - 应该持续下降\n",
    "  - 如果不下降，学习率可能太小或模型容量不足\n",
    "\n",
    "- **橙色线 (Validation)**: 验证集损失\n",
    "  - 用于判断是否过拟合\n",
    "  - 如果验证损失上升而训练损失下降 → 过拟合\n",
    "\n",
    "### 理想曲线特征\n",
    "\n",
    "✅ **健康的训练**:\n",
    "- 训练和验证损失都持续下降\n",
    "- 验证损失略高于训练损失\n",
    "- 两条曲线走势相似\n",
    "\n",
    "⚠️ **过拟合警告**:\n",
    "- 训练损失很低，验证损失很高\n",
    "- 验证损失开始上升\n",
    "\n",
    "⚠️ **欠拟合警告**:\n",
    "- 两个损失都很高且不下降\n",
    "- 需要增加模型容量或训练更长时间\n",
    "\n",
    "### 保存\n",
    "\n",
    "曲线图自动保存到`checkpoints_debug/curve.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_curve",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Training', marker='o')\n",
    "plt.plot(history['val_loss'], label='Validation', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'{SCALE_FACTOR}× SR Training ({LR_PATCH_SIZE}→{HR_PATCH_SIZE})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(CHECKPOINT_DIR / 'curve.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 12. 训练总结报告\n",
    "\n",
    "### 总结内容\n",
    "\n",
    "生成完整的训练总结，包括：\n",
    "\n",
    "#### 配置信息\n",
    "- Patch大小和缩放倍数\n",
    "- Batch size和梯度累积配置\n",
    "- 模型通道数和参数量\n",
    "\n",
    "#### 显存统计\n",
    "- 训练过程中的峰值显存占用\n",
    "- 用于评估是否可以进一步增加batch size或模型大小\n",
    "\n",
    "#### 训练结果\n",
    "- 最佳验证损失\n",
    "- 总训练轮数\n",
    "- 模型保存路径\n",
    "\n",
    "### 文件输出\n",
    "\n",
    "总结报告会：\n",
    "1. 打印到控制台\n",
    "2. 保存为文本文件: `checkpoints_debug/summary.txt`\n",
    "\n",
    "### 后续步骤\n",
    "\n",
    "训练完成后：\n",
    "\n",
    "1. **加载最佳模型**\n",
    "```python\n",
    "checkpoint = torch.load('checkpoints_debug/best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "```\n",
    "\n",
    "2. **推理测试**\n",
    "- 使用滑动窗口将256×256图像超分辨率到2048×2048\n",
    "- 再用bicubic插值放大到4096×4096\n",
    "\n",
    "3. **质量评估**\n",
    "- 计算PSNR, SSIM指标\n",
    "- 与bicubic/其他方法对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary_code",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, _, peak_memory = print_gpu_memory(\"训练结束\")\n",
    "\n",
    "summary = f\"\"\"\n",
    "训练总结\n",
    "{'='*60}\n",
    "\n",
    "配置:\n",
    "  Patch: {LR_PATCH_SIZE}×{LR_PATCH_SIZE} → {HR_PATCH_SIZE}×{HR_PATCH_SIZE} ({SCALE_FACTOR}×)\n",
    "  Batch size: {BATCH_SIZE}\n",
    "  梯度累积: {GRADIENT_ACCUMULATION}\n",
    "  有效batch: {BATCH_SIZE * GRADIENT_ACCUMULATION}\n",
    "  基础通道: {BASE_CHANNELS}\n",
    "  模型参数: {sum(p.numel() for p in model.parameters()):,}\n",
    "\n",
    "显存使用:\n",
    "  峰值显存: {peak_memory:.2f} GB\n",
    "\n",
    "结果:\n",
    "  最佳验证损失: {best_val_loss:.6f}\n",
    "  总训练轮数: {len(history['train_loss'])}\n",
    "\n",
    "模型保存: {CHECKPOINT_DIR / 'best_model.pth'}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "with open(CHECKPOINT_DIR / 'summary.txt', 'w') as f:\n",
    "    f.write(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "train_patch_debug.ipynb",
   "output_path": "out_train_patch_debug_2025-10-14_1306.ipynb",
   "parameters": {},
   "start_time": "2025-10-14T11:06:28.251231",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}