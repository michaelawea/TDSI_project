{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Patch-based 4K Super-Resolution Training with Mixed Precision\n",
    "\n",
    "This notebook implements a **patch-based training strategy** for 16× super-resolution (256×256 → 4096×4096).\n",
    "\n",
    "## Training Strategy:\n",
    "- **Train on patches**: Extract small patches from large images\n",
    "- **LR patch size**: 64×64 or 128×128\n",
    "- **HR patch size**: 1024×1024 or 2048×2048 (16× larger)\n",
    "- **Inference**: Sliding window over full image, stitch results\n",
    "\n",
    "## Advantages:\n",
    "- **Very low memory**: Can train on 4GB GPU\n",
    "- **Fast iteration**: Small patches train quickly\n",
    "- **Scalable**: Works for any resolution\n",
    "- **Mixed precision**: Further reduces memory\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "device_config",
   "metadata": {},
   "source": [
    "## 2. Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'使用设备: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'显存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patch_dataset",
   "metadata": {},
   "source": [
    "## 3. Patch-based Dataset\n",
    "\n",
    "### Key Features:\n",
    "- Randomly extracts patches from 4K images during training\n",
    "- LR patch: 64×64, HR patch: 1024×1024 (16× scale)\n",
    "- Each epoch sees different random patches\n",
    "- Data augmentation: random flip, rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchSRDataset(Dataset):\n",
    "    \"\"\"基于分块的超分辨率数据集\n",
    "    \n",
    "    从4K图像中随机裁剪patch进行训练\n",
    "    \n",
    "    Args:\n",
    "        hr_dir: 4096×4096 HR图像目录\n",
    "        lr_patch_size: LR patch大小（如64或128）\n",
    "        scale_factor: 放大倍数（16）\n",
    "        patches_per_image: 每张图像提取的patch数量\n",
    "        augment: 是否使用数据增强\n",
    "    \"\"\"\n",
    "    def __init__(self, hr_dir, lr_patch_size=64, scale_factor=16, \n",
    "                 patches_per_image=10, augment=True):\n",
    "        self.hr_dir = Path(hr_dir)\n",
    "        self.lr_patch_size = lr_patch_size\n",
    "        self.hr_patch_size = lr_patch_size * scale_factor\n",
    "        self.scale_factor = scale_factor\n",
    "        self.patches_per_image = patches_per_image\n",
    "        self.augment = augment\n",
    "        \n",
    "        # 获取所有HR图片\n",
    "        self.hr_images = sorted(list(self.hr_dir.glob('*.png')))\n",
    "        \n",
    "        print(f\"数据集信息:\")\n",
    "        print(f\"  图像数量: {len(self.hr_images)}\")\n",
    "        print(f\"  LR patch: {lr_patch_size}×{lr_patch_size}\")\n",
    "        print(f\"  HR patch: {self.hr_patch_size}×{self.hr_patch_size}\")\n",
    "        print(f\"  每张图像patch数: {patches_per_image}\")\n",
    "        print(f\"  总patch数/epoch: {len(self.hr_images) * patches_per_image}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.hr_images) * self.patches_per_image\n",
    "    \n",
    "    def augment_patch(self, lr_patch, hr_patch):\n",
    "        \"\"\"数据增强：随机翻转和旋转\"\"\"\n",
    "        # 随机水平翻转\n",
    "        if random.random() > 0.5:\n",
    "            lr_patch = np.fliplr(lr_patch)\n",
    "            hr_patch = np.fliplr(hr_patch)\n",
    "        \n",
    "        # 随机垂直翻转\n",
    "        if random.random() > 0.5:\n",
    "            lr_patch = np.flipud(lr_patch)\n",
    "            hr_patch = np.flipud(hr_patch)\n",
    "        \n",
    "        # 随机旋转90度\n",
    "        k = random.randint(0, 3)\n",
    "        if k > 0:\n",
    "            lr_patch = np.rot90(lr_patch, k)\n",
    "            hr_patch = np.rot90(hr_patch, k)\n",
    "        \n",
    "        return lr_patch.copy(), hr_patch.copy()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 确定是哪张图像\n",
    "        img_idx = idx // self.patches_per_image\n",
    "        \n",
    "        # 读取HR图像（4096×4096）\n",
    "        hr_img = cv2.imread(str(self.hr_images[img_idx]))\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 随机裁剪HR patch\n",
    "        h, w = hr_img.shape[:2]\n",
    "        \n",
    "        # 确保patch在图像范围内\n",
    "        max_y = h - self.hr_patch_size\n",
    "        max_x = w - self.hr_patch_size\n",
    "        \n",
    "        if max_y <= 0 or max_x <= 0:\n",
    "            # 如果图像太小，直接resize\n",
    "            hr_patch = cv2.resize(hr_img, (self.hr_patch_size, self.hr_patch_size))\n",
    "            y, x = 0, 0\n",
    "        else:\n",
    "            y = random.randint(0, max_y)\n",
    "            x = random.randint(0, max_x)\n",
    "            hr_patch = hr_img[y:y+self.hr_patch_size, x:x+self.hr_patch_size]\n",
    "        \n",
    "        # 生成对应的LR patch（下采样）\n",
    "        lr_patch = cv2.resize(hr_patch, (self.lr_patch_size, self.lr_patch_size), \n",
    "                             interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # 数据增强\n",
    "        if self.augment:\n",
    "            lr_patch, hr_patch = self.augment_patch(lr_patch, hr_patch)\n",
    "        \n",
    "        # 转换为tensor，归一化到[0, 1]\n",
    "        lr_tensor = torch.from_numpy(lr_patch.transpose(2, 0, 1)).float() / 255.0\n",
    "        hr_tensor = torch.from_numpy(hr_patch.transpose(2, 0, 1)).float() / 255.0\n",
    "        \n",
    "        return lr_tensor, hr_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_arch",
   "metadata": {},
   "source": [
    "## 4. Efficient U-Net Model for 16× SR\n",
    "\n",
    "### Architecture:\n",
    "- Designed for 16× super-resolution (64×64 → 1024×1024)\n",
    "- Uses progressive upsampling (4 stages of 2× each)\n",
    "- Lightweight with ~10M parameters\n",
    "- BatchNorm for training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"双卷积块\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"下采样块\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"上采样块\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, skip_channels=None):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        \n",
    "        if skip_channels is not None:\n",
    "            self.conv = DoubleConv(in_channels // 2 + skip_channels, out_channels)\n",
    "        else:\n",
    "            self.conv = DoubleConv(in_channels // 2, out_channels)\n",
    "        \n",
    "        self.has_skip = skip_channels is not None\n",
    "    \n",
    "    def forward(self, x1, x2=None):\n",
    "        x1 = self.up(x1)\n",
    "        if self.has_skip and x2 is not None:\n",
    "            x = torch.cat([x2, x1], dim=1)\n",
    "        else:\n",
    "            x = x1\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNetPatch16x(nn.Module):\n",
    "    \"\"\"基于Patch的16×超分辨率U-Net\n",
    "    \n",
    "    输入: 64×64 (或128×128)\n",
    "    输出: 1024×1024 (或2048×2048)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_channels=3, n_classes=3, base_channels=48):\n",
    "        super(UNetPatch16x, self).__init__()\n",
    "        \n",
    "        # 编码器（64 -> 4）\n",
    "        self.inc = DoubleConv(n_channels, base_channels)           # 64×64\n",
    "        self.down1 = Down(base_channels, base_channels * 2)        # 32×32\n",
    "        self.down2 = Down(base_channels * 2, base_channels * 4)    # 16×16\n",
    "        self.down3 = Down(base_channels * 4, base_channels * 8)    # 8×8\n",
    "        self.down4 = Down(base_channels * 8, base_channels * 16)   # 4×4 (bottleneck)\n",
    "        \n",
    "        # 解码器（4 -> 64，带skip连接）\n",
    "        self.up1 = Up(base_channels * 16, base_channels * 8, skip_channels=base_channels * 8)   # 8×8\n",
    "        self.up2 = Up(base_channels * 8, base_channels * 4, skip_channels=base_channels * 4)    # 16×16\n",
    "        self.up3 = Up(base_channels * 4, base_channels * 2, skip_channels=base_channels * 2)    # 32×32\n",
    "        self.up4 = Up(base_channels * 2, base_channels, skip_channels=base_channels)            # 64×64\n",
    "        \n",
    "        # 额外的上采样层（64 -> 1024，16×放大）\n",
    "        # 64 -> 128 -> 256 -> 512 -> 1024\n",
    "        self.up5 = Up(base_channels, base_channels, skip_channels=None)      # 128×128\n",
    "        self.up6 = Up(base_channels, base_channels, skip_channels=None)      # 256×256\n",
    "        self.up7 = Up(base_channels, base_channels, skip_channels=None)      # 512×512\n",
    "        self.up8 = Up(base_channels, base_channels, skip_channels=None)      # 1024×1024\n",
    "        \n",
    "        # 输出层\n",
    "        self.outc = nn.Conv2d(base_channels, n_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 编码\n",
    "        x1 = self.inc(x)       # 48, 64×64\n",
    "        x2 = self.down1(x1)    # 96, 32×32\n",
    "        x3 = self.down2(x2)    # 192, 16×16\n",
    "        x4 = self.down3(x3)    # 384, 8×8\n",
    "        x5 = self.down4(x4)    # 768, 4×4\n",
    "        \n",
    "        # 解码（带skip连接）\n",
    "        x = self.up1(x5, x4)   # 384, 8×8\n",
    "        x = self.up2(x, x3)    # 192, 16×16\n",
    "        x = self.up3(x, x2)    # 96, 32×32\n",
    "        x = self.up4(x, x1)    # 48, 64×64\n",
    "        \n",
    "        # 额外上采样到16×\n",
    "        x = self.up5(x)        # 48, 128×128\n",
    "        x = self.up6(x)        # 48, 256×256\n",
    "        x = self.up7(x)        # 48, 512×512\n",
    "        x = self.up8(x)        # 48, 1024×1024\n",
    "        \n",
    "        # 输出\n",
    "        return self.outc(x)    # 3, 1024×1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## 5. Training Configuration\n",
    "\n",
    "### Memory-Efficient Settings:\n",
    "- **LR patch**: 64×64 (very small)\n",
    "- **HR patch**: 1024×1024 (16× scale)\n",
    "- **Batch size**: 4-8 (fits easily in GPU)\n",
    "- **Mixed precision**: Enabled\n",
    "- **Patches per image**: 10 (more variety per epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练配置\n",
    "LR_PATCH_SIZE = 64          # LR patch大小（64×64或128×128）\n",
    "SCALE_FACTOR = 16           # 放大倍数\n",
    "HR_PATCH_SIZE = LR_PATCH_SIZE * SCALE_FACTOR  # 1024×1024\n",
    "\n",
    "BATCH_SIZE = 4              # batch size（可以设置更大，如8或16）\n",
    "LEARNING_RATE = 2e-4        # 学习率\n",
    "NUM_EPOCHS = 50             # 训练轮数\n",
    "PATCHES_PER_IMAGE = 10      # 每张图像提取的patch数\n",
    "\n",
    "BASE_CHANNELS = 48          # 模型基础通道数（可调整：32/48/64）\n",
    "USE_MIXED_PRECISION = True  # 混合精度训练\n",
    "TRAIN_SPLIT = 0.9           # 训练集比例\n",
    "\n",
    "# 数据路径\n",
    "HR_DIR = './dataset_4k/high_resolution'\n",
    "CHECKPOINT_DIR = Path('./checkpoints_patch')\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"训练配置:\")\n",
    "print(f\"  LR patch大小: {LR_PATCH_SIZE}×{LR_PATCH_SIZE}\")\n",
    "print(f\"  HR patch大小: {HR_PATCH_SIZE}×{HR_PATCH_SIZE}\")\n",
    "print(f\"  放大倍数: {SCALE_FACTOR}×\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  训练轮数: {NUM_EPOCHS}\")\n",
    "print(f\"  每张图像patches: {PATCHES_PER_IMAGE}\")\n",
    "print(f\"  混合精度: {'启用' if USE_MIXED_PRECISION else '禁用'}\")\n",
    "print(f\"  模型基础通道数: {BASE_CHANNELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading",
   "metadata": {},
   "source": [
    "## 6. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_loader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集\n",
    "full_dataset = PatchSRDataset(\n",
    "    hr_dir=HR_DIR,\n",
    "    lr_patch_size=LR_PATCH_SIZE,\n",
    "    scale_factor=SCALE_FACTOR,\n",
    "    patches_per_image=PATCHES_PER_IMAGE,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = int(TRAIN_SPLIT * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,  # 可以使用多进程加载\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\n训练集patches: {train_size}\")\n",
    "print(f\"验证集patches: {val_size}\")\n",
    "print(f\"训练批次数: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize_patches",
   "metadata": {},
   "source": [
    "## 7. Visualize Sample Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化一些patch样本\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i in range(5):\n",
    "    lr_patch, hr_patch = full_dataset[i]\n",
    "    \n",
    "    # 转换为numpy\n",
    "    lr_np = lr_patch.numpy().transpose(1, 2, 0)\n",
    "    hr_np = hr_patch.numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    # 显示LR patch\n",
    "    axes[0, i].imshow(lr_np)\n",
    "    axes[0, i].set_title(f'LR {LR_PATCH_SIZE}×{LR_PATCH_SIZE}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # 显示HR patch（下采样显示）\n",
    "    hr_display = cv2.resize(hr_np, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "    axes[1, i].imshow(hr_display)\n",
    "    axes[1, i].set_title(f'HR {HR_PATCH_SIZE}×{HR_PATCH_SIZE}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CHECKPOINT_DIR / 'patch_samples.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"样本已保存至: {CHECKPOINT_DIR / 'patch_samples.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_init",
   "metadata": {},
   "source": [
    "## 8. Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model = UNetPatch16x(n_channels=3, n_classes=3, base_channels=BASE_CHANNELS).to(device)\n",
    "\n",
    "# 统计参数\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\n模型参数总数: {total_params:,}\")\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "\n",
    "# 混合精度scaler\n",
    "scaler = GradScaler() if USE_MIXED_PRECISION else None\n",
    "\n",
    "print(f\"优化器: Adam\")\n",
    "print(f\"学习率: {LEARNING_RATE}\")\n",
    "print(f\"损失函数: L1 Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_functions",
   "metadata": {},
   "source": [
    "## 9. Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_val_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, scaler, device, use_amp=True):\n",
    "    \"\"\"训练一个epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='训练')\n",
    "    for lr_patches, hr_patches in pbar:\n",
    "        lr_patches = lr_patches.to(device)\n",
    "        hr_patches = hr_patches.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 混合精度训练\n",
    "        if use_amp and scaler is not None:\n",
    "            with autocast():\n",
    "                outputs = model(lr_patches)\n",
    "                loss = criterion(outputs, hr_patches)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(lr_patches)\n",
    "            loss = criterion(outputs, hr_patches)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device, use_amp=True):\n",
    "    \"\"\"验证\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for lr_patches, hr_patches in val_loader:\n",
    "            lr_patches = lr_patches.to(device)\n",
    "            hr_patches = hr_patches.to(device)\n",
    "            \n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(lr_patches)\n",
    "                    loss = criterion(outputs, hr_patches)\n",
    "            else:\n",
    "                outputs = model(lr_patches)\n",
    "                loss = criterion(outputs, hr_patches)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_loop",
   "metadata": {},
   "source": [
    "## 10. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练历史\n",
    "history = {'train_loss': [], 'val_loss': []}\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"\\n开始训练...\\n\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 训练\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, scaler, device, USE_MIXED_PRECISION)\n",
    "    \n",
    "    # 验证\n",
    "    val_loss = validate(model, val_loader, criterion, device, USE_MIXED_PRECISION)\n",
    "    \n",
    "    # 记录\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"\\n训练损失: {train_loss:.6f}\")\n",
    "    print(f\"验证损失: {val_loss:.6f}\")\n",
    "    print(f\"学习率: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'config': {\n",
    "                'lr_patch_size': LR_PATCH_SIZE,\n",
    "                'scale_factor': SCALE_FACTOR,\n",
    "                'base_channels': BASE_CHANNELS\n",
    "            }\n",
    "        }, CHECKPOINT_DIR / 'best_model.pth')\n",
    "        print(f\"✓ 保存最佳模型 (验证损失: {val_loss:.6f})\")\n",
    "    \n",
    "    # 定期保存\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, CHECKPOINT_DIR / f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        print(f\"✓ 保存检查点: epoch_{epoch+1}\")\n",
    "\n",
    "print(\"\\n训练完成！\")\n",
    "print(f\"最佳验证损失: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot_curve",
   "metadata": {},
   "source": [
    "## 11. Training Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Training Loss', marker='o')\n",
    "plt.plot(history['val_loss'], label='Validation Loss', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (L1)')\n",
    "plt.title('Patch-based Training Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(CHECKPOINT_DIR / 'training_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"训练曲线已保存: {CHECKPOINT_DIR / 'training_curve.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference",
   "metadata": {},
   "source": [
    "## 12. Inference with Sliding Window\n",
    "\n",
    "### Sliding Window Strategy:\n",
    "- Divide 256×256 LR image into overlapping 64×64 patches\n",
    "- Process each patch → 1024×1024 HR patch\n",
    "- Stitch all HR patches → 4096×4096 final image\n",
    "- Use overlap and blending to avoid seams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_inference(model, lr_img_256, patch_size=64, overlap=16, device='cuda'):\n",
    "    \"\"\"\n",
    "    使用滑动窗口对256×256图像进行16×超分辨率\n",
    "    \n",
    "    Args:\n",
    "        model: 训练好的模型\n",
    "        lr_img_256: 256×256的LR图像 (torch.Tensor, shape: 1,3,256,256)\n",
    "        patch_size: patch大小（64）\n",
    "        overlap: patch之间的重叠（16，用于平滑拼接）\n",
    "        device: 设备\n",
    "    \n",
    "    Returns:\n",
    "        sr_img_4k: 4096×4096的SR图像 (torch.Tensor)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    _, _, h, w = lr_img_256.shape\n",
    "    stride = patch_size - overlap\n",
    "    \n",
    "    # 计算需要多少个patch\n",
    "    num_patches_h = (h - overlap) // stride\n",
    "    num_patches_w = (w - overlap) // stride\n",
    "    \n",
    "    # 输出图像大小\n",
    "    out_h = num_patches_h * patch_size * 16\n",
    "    out_w = num_patches_w * patch_size * 16\n",
    "    \n",
    "    # 创建输出canvas\n",
    "    sr_img = torch.zeros(1, 3, out_h, out_w).to(device)\n",
    "    weight_map = torch.zeros(1, 1, out_h, out_w).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            for i in range(num_patches_h):\n",
    "                for j in range(num_patches_w):\n",
    "                    # 提取LR patch\n",
    "                    y = i * stride\n",
    "                    x = j * stride\n",
    "                    lr_patch = lr_img_256[:, :, y:y+patch_size, x:x+patch_size]\n",
    "                    \n",
    "                    # 超分辨率\n",
    "                    sr_patch = model(lr_patch.to(device))\n",
    "                    \n",
    "                    # 放置到输出图像\n",
    "                    out_y = i * stride * 16\n",
    "                    out_x = j * stride * 16\n",
    "                    sr_img[:, :, out_y:out_y+patch_size*16, out_x:out_x+patch_size*16] += sr_patch\n",
    "                    weight_map[:, :, out_y:out_y+patch_size*16, out_x:out_x+patch_size*16] += 1\n",
    "    \n",
    "    # 平均重叠区域\n",
    "    sr_img = sr_img / weight_map\n",
    "    \n",
    "    return sr_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_inference",
   "metadata": {},
   "source": [
    "## 13. Test Inference on Full Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型\n",
    "checkpoint = torch.load(CHECKPOINT_DIR / 'best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"已加载最佳模型 (Epoch {checkpoint['epoch']+1}, 验证损失: {checkpoint['val_loss']:.6f})\")\n",
    "\n",
    "# 读取测试图像\n",
    "test_hr_path = list(Path(HR_DIR).glob('*.png'))[0]\n",
    "test_hr_4k = cv2.imread(str(test_hr_path))\n",
    "test_hr_4k = cv2.cvtColor(test_hr_4k, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 生成256×256的LR图像\n",
    "test_lr_256 = cv2.resize(test_hr_4k, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "lr_tensor = torch.from_numpy(test_lr_256.transpose(2, 0, 1)).float() / 255.0\n",
    "lr_tensor = lr_tensor.unsqueeze(0)\n",
    "\n",
    "print(f\"\\n输入图像: {lr_tensor.shape}\")\n",
    "print(\"开始滑动窗口推理...\")\n",
    "\n",
    "# 滑动窗口推理\n",
    "sr_tensor = sliding_window_inference(model, lr_tensor, patch_size=LR_PATCH_SIZE, \n",
    "                                     overlap=16, device=device)\n",
    "\n",
    "print(f\"输出图像: {sr_tensor.shape}\")\n",
    "\n",
    "# 可视化结果\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# LR输入\n",
    "axes[0].imshow(test_lr_256)\n",
    "axes[0].set_title('Input (256×256)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# SR输出（下采样显示）\n",
    "sr_np = sr_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
    "sr_np = np.clip(sr_np, 0, 1)\n",
    "sr_display = cv2.resize(sr_np, (512, 512), interpolation=cv2.INTER_AREA)\n",
    "axes[1].imshow(sr_display)\n",
    "axes[1].set_title(f'SR Output ({sr_tensor.shape[2]}×{sr_tensor.shape[3]})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Ground Truth（下采样显示）\n",
    "hr_np = test_hr_4k / 255.0\n",
    "hr_display = cv2.resize(hr_np, (512, 512), interpolation=cv2.INTER_AREA)\n",
    "axes[2].imshow(hr_display)\n",
    "axes[2].set_title('Ground Truth (4096×4096)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CHECKPOINT_DIR / 'inference_result.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n推理结果已保存: {CHECKPOINT_DIR / 'inference_result.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval",
   "metadata": {},
   "source": [
    "## 14. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def evaluate_full_images(model, hr_dir, num_samples=5, patch_size=64, device='cuda'):\n",
    "    \"\"\"在完整图像上评估模型\"\"\"\n",
    "    hr_images = sorted(list(Path(hr_dir).glob('*.png')))[:num_samples]\n",
    "    \n",
    "    psnr_scores = []\n",
    "    ssim_scores = []\n",
    "    \n",
    "    for hr_path in tqdm(hr_images, desc='评估'):\n",
    "        # 读取HR图像\n",
    "        hr_4k = cv2.imread(str(hr_path))\n",
    "        hr_4k = cv2.cvtColor(hr_4k, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 生成LR图像\n",
    "        lr_256 = cv2.resize(hr_4k, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        lr_tensor = torch.from_numpy(lr_256.transpose(2, 0, 1)).float() / 255.0\n",
    "        lr_tensor = lr_tensor.unsqueeze(0)\n",
    "        \n",
    "        # 推理\n",
    "        sr_tensor = sliding_window_inference(model, lr_tensor, patch_size=patch_size, \n",
    "                                            overlap=16, device=device)\n",
    "        \n",
    "        # 转换为numpy\n",
    "        sr_np = sr_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
    "        sr_np = np.clip(sr_np, 0, 1)\n",
    "        hr_np = hr_4k / 255.0\n",
    "        \n",
    "        # 裁剪到相同大小（如果有差异）\n",
    "        min_h = min(sr_np.shape[0], hr_np.shape[0])\n",
    "        min_w = min(sr_np.shape[1], hr_np.shape[1])\n",
    "        sr_np = sr_np[:min_h, :min_w]\n",
    "        hr_np = hr_np[:min_h, :min_w]\n",
    "        \n",
    "        # 下采样计算指标\n",
    "        sr_small = cv2.resize(sr_np, (1024, 1024), interpolation=cv2.INTER_AREA)\n",
    "        hr_small = cv2.resize(hr_np, (1024, 1024), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # 计算指标\n",
    "        psnr_score = psnr(hr_small, sr_small, data_range=1.0)\n",
    "        ssim_score = ssim(hr_small, sr_small, data_range=1.0, channel_axis=2)\n",
    "        \n",
    "        psnr_scores.append(psnr_score)\n",
    "        ssim_scores.append(ssim_score)\n",
    "    \n",
    "    print(f\"\\n=== 评估结果 ===\")\n",
    "    print(f\"平均PSNR: {np.mean(psnr_scores):.2f} dB\")\n",
    "    print(f\"平均SSIM: {np.mean(ssim_scores):.4f}\")\n",
    "    \n",
    "    return np.mean(psnr_scores), np.mean(ssim_scores)\n",
    "\n",
    "# 运行评估\n",
    "avg_psnr, avg_ssim = evaluate_full_images(model, HR_DIR, num_samples=5, \n",
    "                                          patch_size=LR_PATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 15. Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = f\"\"\"\n",
    "基于Patch的4K超分辨率训练总结\n",
    "{'='*60}\n",
    "\n",
    "训练策略: Patch-based Training\n",
    "混合精度: {'启用' if USE_MIXED_PRECISION else '禁用'}\n",
    "\n",
    "数据配置:\n",
    "  LR patch大小: {LR_PATCH_SIZE}×{LR_PATCH_SIZE}\n",
    "  HR patch大小: {HR_PATCH_SIZE}×{HR_PATCH_SIZE}\n",
    "  缩放倍数: {SCALE_FACTOR}×\n",
    "  每张图像patches: {PATCHES_PER_IMAGE}\n",
    "\n",
    "模型配置:\n",
    "  架构: UNetPatch16x\n",
    "  基础通道数: {BASE_CHANNELS}\n",
    "  参数量: {total_params:,}\n",
    "\n",
    "训练配置:\n",
    "  Batch size: {BATCH_SIZE}\n",
    "  训练轮数: {NUM_EPOCHS}\n",
    "  初始学习率: {LEARNING_RATE}\n",
    "  优化器: Adam\n",
    "  损失函数: L1 Loss\n",
    "\n",
    "训练结果:\n",
    "  最佳验证损失: {best_val_loss:.6f}\n",
    "  平均PSNR: {avg_psnr:.2f} dB\n",
    "  平均SSIM: {avg_ssim:.4f}\n",
    "\n",
    "模型保存位置: {CHECKPOINT_DIR / 'best_model.pth'}\n",
    "\n",
    "推理方法:\n",
    "  使用滑动窗口（overlap=16）拼接完整4K图像\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "with open(CHECKPOINT_DIR / 'training_summary.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(f\"\\n总结已保存至: {CHECKPOINT_DIR / 'training_summary.txt'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
